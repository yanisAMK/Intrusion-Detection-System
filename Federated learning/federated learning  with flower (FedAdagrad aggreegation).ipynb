{"cells":[{"cell_type":"markdown","metadata":{"id":"kVQL9E1Mz0wp"},"source":["notes on memoire:\n","\n","framework: flower\n","\n","federated learning setting : Cross_silo"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"c-os3hA5Wnp3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687676177059,"user_tz":-60,"elapsed":11991,"user":{"displayName":"collab","userId":"14061672705760794442"}},"outputId":"1ac7c8f5-0e8b-4cc7-8e3c-8caae489b4ce"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.12.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.51.3)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.8.0)\n","Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.10)\n","Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.0)\n","Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.22.4)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.1)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.3)\n","Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.6.3)\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.32.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.40.0)\n","Requirement already satisfied: ml-dtypes>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (0.2.0)\n","Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (1.10.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.4.3)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.27.1)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.3.6)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (5.3.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2023.5.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.4)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (2.1.3)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.5.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: ray in /usr/local/lib/python3.10/dist-packages (2.5.1)\n","Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from ray) (23.1.0)\n","Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from ray) (8.1.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from ray) (3.12.2)\n","Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from ray) (4.3.3)\n","Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray) (1.0.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from ray) (23.1)\n","Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.10/dist-packages (from ray) (3.20.3)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from ray) (6.0)\n","Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray) (1.3.1)\n","Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray) (1.3.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ray) (2.27.1)\n","Requirement already satisfied: grpcio<=1.51.3,>=1.42.0 in /usr/local/lib/python3.10/dist-packages (from ray) (1.51.3)\n","Requirement already satisfied: numpy>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from ray) (1.22.4)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray) (0.19.3)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ray) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ray) (2023.5.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->ray) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ray) (3.4)\n"]}],"source":["!pip install -q flwr[simulation]\n","!pip install tensorflow\n","!pip install ray"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"394PM4IQlNQe","executionInfo":{"status":"ok","timestamp":1687676177060,"user_tz":-60,"elapsed":25,"user":{"displayName":"collab","userId":"14061672705760794442"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":24,"metadata":{"id":"gsBPEQxykD-R","colab":{"base_uri":"https://localhost:8080/","height":55},"executionInfo":{"status":"ok","timestamp":1687676177060,"user_tz":-60,"elapsed":24,"user":{"displayName":"collab","userId":"14061672705760794442"}},"outputId":"26aa1701-15ee-4238-a750-c4868eced1e8"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'import os\\nos.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = \"true\"\\nimport tensorflow as tf\\nphysical_devices = tf.config.list_physical_devices(\"GPU\")\\ntf.config.set_visible_devices(physical_devices, \"GPU\")'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":24}],"source":["\"\"\"import os\n","os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = \"true\"\n","import tensorflow as tf\n","physical_devices = tf.config.list_physical_devices(\"GPU\")\n","tf.config.set_visible_devices(physical_devices, \"GPU\")\"\"\""]},{"cell_type":"code","execution_count":25,"metadata":{"id":"7MuH09SBH_yA","executionInfo":{"status":"ok","timestamp":1687676177061,"user_tz":-60,"elapsed":11,"user":{"displayName":"collab","userId":"14061672705760794442"}}},"outputs":[],"source":["from collections import OrderedDict\n","from typing import List, Tuple\n","import tensorflow as tf\n","import flwr as fl\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","from flwr.common import Metrics\n","import keras\n","tf.keras.utils.set_random_seed(7)\n","tf.config.experimental.enable_op_determinism()\n"]},{"cell_type":"code","source":["config = \"NSLKDD FedAdgrad\""],"metadata":{"id":"2YjqECINPv6s","executionInfo":{"status":"ok","timestamp":1687676177062,"user_tz":-60,"elapsed":11,"user":{"displayName":"collab","userId":"14061672705760794442"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","execution_count":27,"metadata":{"id":"vAV0jZbh4On7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687676181664,"user_tz":-60,"elapsed":4613,"user":{"displayName":"collab","userId":"14061672705760794442"}},"outputId":"c0760f1c-b0a3-4cc4-a427-f48f633209fb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["#importing dataseet\n","from google.colab import drive\n","from sklearn.model_selection import train_test_split\n","drive.mount('/content/drive')\n","\n","train_df=pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/nslkdd/multi/KDDTrain_multi_combined.txt\")\n","test_df=pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/nslkdd/multi/KDDTest_multi_combined.txt\")"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"2uE21BzOILy9","executionInfo":{"status":"ok","timestamp":1687676182150,"user_tz":-60,"elapsed":491,"user":{"displayName":"collab","userId":"14061672705760794442"}}},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn import metrics\n","from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score, confusion_matrix, classification_report\n","import seaborn as sns\n","\n","def evaluate_model(model, X_test, y_true):\n","    # Step 2: Make predictions\n","    y_pred_prob = model.predict(X_test)\n","    y_pred = np.argmax(y_pred_prob, axis=1)\n","\n","    # Step 3: Calculate accuracy\n","    accuracy = accuracy_score(y_true, y_pred)\n","\n","    # Step 4: Calculate precision\n","    precision = precision_score(y_true, y_pred, average='weighted')\n","\n","    # Step 5: Calculate F1-score\n","    f1score = f1_score(y_true, y_pred, average='weighted')\n","\n","    # Step 6: Calculate Recall\n","    recall = recall_score(y_true, y_pred, average='weighted')\n","\n","    print(\"Accuracy:\", accuracy)\n","    print(\"Precision:\", precision)\n","    print(\"Recall:\", recall)\n","    print(\"F1-score:\", f1score)\n","\n","    # Generate the classification report\n","    classes = ['Normal', 'DoS', 'Probe', 'R2L', 'U2R']\n","    print(\"\\n\\n\",classification_report(y_test, y_pred))\n","\n","    # Step 6: Calculate confusion matrix\n","    cm = confusion_matrix(y_true, y_pred)\n","\n","\n","    # Create a figure and axis\n","    fig, ax = plt.subplots(figsize=(4, 3))\n","\n","    # Plot the confusion matrix as a heatmap\n","    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False, ax=ax)\n","\n","    # Set labels and title\n","\n","    ax.set_xlabel('Predicted labels')\n","    ax.set_ylabel('True labels')\n","    ax.set_title('Confusion Matrix')\n","\n","    # Set x-axis and y-axis tick labels\n","    ax.xaxis.set_ticklabels(classes)\n","    ax.yaxis.set_ticklabels(classes)\n","\n","    # Rotate the tick labels for better visibility\n","    plt.xticks(rotation=45)\n","    plt.yticks(rotation=0)\n","\n","    # Display the plot\n","    plt.show()\n","\n","    num_classes = cm.shape[0]\n","    for class_idx in range(num_classes):\n","        row = cm[class_idx]\n","\n","        tn = np.sum(np.delete(np.delete(cm, class_idx, axis=0), class_idx, axis=1))\n","        fp = np.sum(row) - cm[class_idx, class_idx]\n","        fn = np.sum(row) - cm[class_idx, class_idx]\n","        tp = cm[class_idx, class_idx]\n","\n","        false_positive_rate = fp / (fp + tn)\n","        false_negative_rate = fn / (fn + tp)\n","\n","        print(\"Class:\", class_idx)\n","        print(\"False Positive Rate:\", false_positive_rate)\n","        print(\"False Negative Rate:\", false_negative_rate)\n","        print()"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"I702SWxoOm0g","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687676182151,"user_tz":-60,"elapsed":12,"user":{"displayName":"collab","userId":"14061672705760794442"}},"outputId":"510807d6-e9cf-4af9-ecb9-f5123b4079c2"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([3, 1, 2, 4])"]},"metadata":{},"execution_count":29}],"source":["train_set = train_df\n","test_set = test_df\n","atk_labels = train_set['class'].unique()[train_set['class'].unique() != 0]\n","train_set\n","atk_labels"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"MF3sT9_0htw4","executionInfo":{"status":"ok","timestamp":1687676182151,"user_tz":-60,"elapsed":9,"user":{"displayName":"collab","userId":"14061672705760794442"}}},"outputs":[],"source":["#Create a Keras model constructor\n","from keras.models import Sequential\n","from keras.layers import Dense, Conv1D, MaxPooling1D, LSTM, Dropout, Flatten\n","\n","def build_model():\n","  # Define your CNN-LSTM model\n","  cnn_lstm = Sequential()\n","  cnn_lstm.add(Dense(32, activation='relu', input_shape=(117, 1)))\n","  cnn_lstm.add(Conv1D(128, kernel_size=3, activation='relu'))\n","  cnn_lstm.add(MaxPooling1D(pool_size=2))\n","  cnn_lstm.add(LSTM(128, return_sequences=True))\n","  cnn_lstm.add(Dropout(0.3))\n","  cnn_lstm.add(Flatten())\n","  cnn_lstm.add(Dense(128, activation='relu'))\n","  cnn_lstm.add(Dense(5, activation='sigmoid'))\n","  optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n","  # Compile the cnn_lstm\n","  cnn_lstm.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","\n","  return cnn_lstm"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"eyMQWIUFs-uk","executionInfo":{"status":"ok","timestamp":1687676182151,"user_tz":-60,"elapsed":9,"user":{"displayName":"collab","userId":"14061672705760794442"}}},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn import metrics\n","from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score, confusion_matrix, classification_report\n","import seaborn as sns\n","\n","def evaluate_model1(model, X_test, y_true):\n","\n","    loss, _ = model.evaluate(x_test, y_true, verbose=0)\n","    # Step 2: Make predictions\n","    y_pred_prob = model.predict(X_test)\n","    y_pred = np.argmax(y_pred_prob, axis=1)\n","\n","    # Step 3: Calculate accuracy\n","    accuracy = accuracy_score(y_true, y_pred)\n","\n","    # Step 4: Calculate precision\n","    precision = precision_score(y_true, y_pred, average='weighted', zero_division=1.0)\n","\n","    # Step 5: Calculate F1-score\n","    f1score = f1_score(y_true, y_pred, average='weighted')\n","\n","    # Step 6: Calculate Recall\n","    recall = recall_score(y_true, y_pred, average='weighted')\n","\n","    # Step 7: Calculate confusion matrix\n","    cm = confusion_matrix(y_true, y_pred)\n","\n","    return cm, {\n","        \"accuracy\" : accuracy,\n","        \"precision\" : precision,\n","        \"recall\" : recall,\n","        \"f1-score\": f1score\n","    }, loss"]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n","\n","def calculate_metrics(y_true, y_pred):\n","    \"\"\"\n","    Calculate classification metrics for the given true labels and predicted labels.\n","    Returns a dictionary of metric values.\n","    \"\"\"\n","    metrics = {}\n","    y_pred =np.argmax(y_pred, axis=1)\n","    metrics['Accuracy'] = accuracy_score(y_true, y_pred)\n","    metrics['Recall'] = recall_score(y_true, y_pred,average='weighted')\n","    metrics['Precision'] = precision_score(y_true, y_pred,average='weighted')\n","    metrics['F1-score'] = f1_score(y_true, y_pred,average='weighted')\n","\n","    return metrics\n","\n","def write_metrics_to_dataframe(configuration_name, metrics_dict, df):\n","    \"\"\"\n","    Write the classification metrics from the metrics dictionary to a DataFrame.\n","    The metrics are appended as a new row to the given DataFrame along with the configuration name.\n","    \"\"\"\n","    metrics_dict['Configuration'] = configuration_name\n","    df = df.append(metrics_dict, ignore_index=True)\n","    return df\n","\n","# Initializing the DataFrame\n","columns = ['Configuration', 'Accuracy', 'Recall', 'Precision', 'F1-score']\n","result_df = pd.DataFrame(columns=columns)\n"],"metadata":{"id":"V84iWsBaPnT1","executionInfo":{"status":"ok","timestamp":1687676182152,"user_tz":-60,"elapsed":10,"user":{"displayName":"collab","userId":"14061672705760794442"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","execution_count":33,"metadata":{"id":"zYtDBX1sPb3w","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687676182152,"user_tz":-60,"elapsed":10,"user":{"displayName":"collab","userId":"14061672705760794442"}},"outputId":"b937fce7-9de1-4601-8dcb-bd25433e0f57"},"outputs":[{"output_type":"stream","name":"stdout","text":["partition size : 25899\n","client:  0\n","classes removed  1\n","classes:  [0 3 2 4]\n","\n","client:  1\n","classes removed  2\n","classes:  [1 0 3 4]\n","\n","client:  2\n","classes removed  3\n","classes:  [0 2 1 4]\n","\n","client:  3\n","classes removed  4\n","classes:  [1 0 2 3]\n","\n"]}],"source":["import math\n","from sklearn.utils import shuffle\n","\n","nb_clients = 4\n","\n","\n","train_set = shuffle(train_set)\n","\n","#calculating partition size for each client\n","partition_size = len(train_set)//nb_clients\n","print(\"partition size :\", partition_size)\n","client_partitions = []\n","\n","for i in range (nb_clients):\n","  #index range for the partition\n","  from_i, to_i = i*partition_size, (i+1)*partition_size\n","  #getting the partition\n","  partition = train_set[from_i: to_i]\n","\n","  #not randomly removeing atk classes\n","  class_to_remove = i+1\n","  print(\"client: \", i)\n","  print(\"classes removed \", class_to_remove)\n","  partition = partition[partition['class'] != class_to_remove]\n","  print(\"classes: \", partition['class'].unique())\n","  print()\n","  y_part = partition['class']\n","  x_part = partition.drop('class', axis = 1)\n","  client_partitions.append((x_part, y_part, class_to_remove))\n","\n"]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mYecls5xQGT5","executionInfo":{"status":"ok","timestamp":1687676218450,"user_tz":-60,"elapsed":36305,"user":{"displayName":"collab","userId":"14061672705760794442"}},"outputId":"337ca553-8fc9-410a-eaf1-0c8953a55883"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","260/260 [==============================] - 16s 9ms/step - loss: 0.2173 - accuracy: 0.9243\n","Epoch 2/10\n","260/260 [==============================] - 2s 9ms/step - loss: 0.1032 - accuracy: 0.9610\n","Epoch 3/10\n","260/260 [==============================] - 2s 9ms/step - loss: 0.0877 - accuracy: 0.9672\n","Epoch 4/10\n","260/260 [==============================] - 2s 8ms/step - loss: 0.0802 - accuracy: 0.9688\n","Epoch 5/10\n","260/260 [==============================] - 2s 8ms/step - loss: 0.0707 - accuracy: 0.9734\n","Epoch 6/10\n","260/260 [==============================] - 2s 8ms/step - loss: 0.0657 - accuracy: 0.9756\n","Epoch 7/10\n","260/260 [==============================] - 2s 8ms/step - loss: 0.0634 - accuracy: 0.9760\n","Epoch 8/10\n","260/260 [==============================] - 2s 8ms/step - loss: 0.0594 - accuracy: 0.9764\n","Epoch 9/10\n","260/260 [==============================] - 2s 8ms/step - loss: 0.0561 - accuracy: 0.9764\n","Epoch 10/10\n","260/260 [==============================] - 2s 8ms/step - loss: 0.0526 - accuracy: 0.9796\n"]}],"source":["model = build_model()\n","part = client_partitions[0]\n","history = model.fit(part[0], part[1], batch_size = 64, epochs = 10)"]},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3-F8zJiDa75_","executionInfo":{"status":"ok","timestamp":1687676224576,"user_tz":-60,"elapsed":6132,"user":{"displayName":"collab","userId":"14061672705760794442"}},"outputId":"88464d5f-820c-4d1e-a0b7-59c986acab5b"},"outputs":[{"output_type":"stream","name":"stdout","text":["696/696 [==============================] - 3s 3ms/step\n"]},{"output_type":"execute_result","data":{"text/plain":["(array([[11290,     0,    47,   125,     0],\n","        [ 1175,     0,  6819,    60,     0],\n","        [   63,     0,  2061,     0,     1],\n","        [   75,     0,     0,   493,     2],\n","        [   13,     0,     0,     7,    29]]),\n"," {'accuracy': 0.6232255166217431,\n","  'precision': 0.8650734463127728,\n","  'recall': 0.6232255166217431,\n","  'f1-score': 0.540177795591448},\n"," 9.282808303833008)"]},"metadata":{},"execution_count":35}],"source":["y_test = test_set['class']\n","x_test = test_set.drop('class', axis = 1)\n","evaluate_model1(model, x_test, y_test)\n"]},{"cell_type":"code","execution_count":36,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hQqsYTLC8930","executionInfo":{"status":"ok","timestamp":1687676224576,"user_tz":-60,"elapsed":8,"user":{"displayName":"collab","userId":"14061672705760794442"}},"outputId":"4d834650-6cd9-40d7-9c0b-e357deb96d5b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["4"]},"metadata":{},"execution_count":36}],"source":["len(client_partitions)"]},{"cell_type":"code","execution_count":37,"metadata":{"id":"uII4SHmWl7wD","executionInfo":{"status":"ok","timestamp":1687676224577,"user_tz":-60,"elapsed":6,"user":{"displayName":"collab","userId":"14061672705760794442"}}},"outputs":[],"source":["#Creating a Client Class\n","class FlwrClient(fl.client.NumPyClient):\n","    def __init__(self, cid, X, y):\n","        self.X_train = X\n","        self.y_train = y\n","        self.cid = cid\n","\n","        self.model = build_model()\n","\n","    def get_parameters(self, config):\n","        return self.model.get_weights()\n","\n","    def fit(self, parameters, config):\n","        self.model.set_weights(parameters)\n","        self.model.fit(\n","            self.X_train,\n","            self.y_train,\n","            epochs=config[\"epochs\"],\n","            batch_size=config[\"batch_size\"],\n","            verbose=0,  # suppress logging for clients\n","        )\n","        return self.model.get_weights(), len(self.X_train), {}\n","\n","    def evaluate(self, parameters, config):\n","        model.set_weights(parameters)\n","        loss, accuracy = model.evaluate(x_test, y_test)\n","        return loss, len(x_test), {\"accuracy\": float(accuracy)}"]},{"cell_type":"code","execution_count":38,"metadata":{"id":"1sIw8yZlBS-l","executionInfo":{"status":"ok","timestamp":1687676224577,"user_tz":-60,"elapsed":5,"user":{"displayName":"collab","userId":"14061672705760794442"}}},"outputs":[],"source":["#create a client IDs list\n","client_ids_list = [f\"client_{i}\" for i in range(nb_clients)]\n","\n","#create a dictionary {client_id: x_train_partition}\n","clientIds_wParts = dict(zip(client_ids_list, client_partitions))\n","\n","#function for generating clients input is like \"client_5\"\n","def gen_client( client_id: str) -> fl.client.NumPyClient:\n","  return FlwrClient(\n","      client_id,\n","      clientIds_wParts[client_id][0],\n","      clientIds_wParts[client_id][1]\n","  )"]},{"cell_type":"code","execution_count":39,"metadata":{"id":"mRovbgnGpSl-","executionInfo":{"status":"ok","timestamp":1687676225200,"user_tz":-60,"elapsed":628,"user":{"displayName":"collab","userId":"14061672705760794442"}}},"outputs":[],"source":["from typing import Optional, Dict\n","from flwr.common import Scalar, NDArrays, ndarrays_to_parameters\n","\n","fl_weights = None\n","initial_params = ndarrays_to_parameters(build_model().get_weights())\n","\n","def eval_round_model(server_round: int, parameters: NDArrays, config: Dict[str, Scalar]) -> Optional[Tuple[float, Dict[str, Scalar]]]:\n","  if server_round == 5: #if we are at the last round (10th)\n","    global fl_weights\n","    fl_weights = parameters\n","\n","  #update the global model with latest weights\n","  model.set_weights(parameters)\n","  _, metrics, loss = evaluate_model1(model, x_test, y_test)\n","  return loss, metrics\n","\n","strategy = fl.server.strategy.FedAdagrad(\n","    fraction_fit = 1.0,           # Sample ALL available clients for training\n","    min_fit_clients = 4,         # Never sample less than 7 clients for training\n","    min_available_clients = 4,   # Wait until all 7 clients are available\n","    evaluate_fn = eval_round_model,    # Evaluate the model after each round using this function\n","    on_fit_config_fn = lambda rnd: {  # Use this function to configure the training\n","        \"epochs\": 10,                # Train for 20 epochs\n","        \"batch_size\": 64,           # Use a batch size of 64\n","    },\n","    initial_parameters = initial_params,    # Initialize the model with these parameters\n",")\n"]},{"cell_type":"code","execution_count":40,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tWcoIgFjroui","executionInfo":{"status":"ok","timestamp":1687676226208,"user_tz":-60,"elapsed":1013,"user":{"displayName":"collab","userId":"14061672705760794442"}},"outputId":"ef90a41a-799b-4495-ca1c-0710ffb1bb27"},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of clients: 4\n","  client_0: \t X: (16628, 117), classes manquantes : 1\n","  client_1: \t X: (23420, 117), classes manquantes : 2\n","  client_2: \t X: (25245, 117), classes manquantes : 3\n","  client_3: \t X: (25865, 117), classes manquantes : 4\n"]}],"source":["print(f\"Number of clients: {nb_clients}\")\n","clients = []\n","for key, value in clientIds_wParts.items():\n","  print(f\"  {key}: \\t X: {value[0].shape}, classes manquantes : {value[2]}\")\n","  client = FlwrClient(cid = key, X = value[0], y = value[1])\n","  clients.append(client)\n"]},{"cell_type":"code","execution_count":41,"metadata":{"id":"NzcsK-_21hyW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687678062365,"user_tz":-60,"elapsed":1836166,"user":{"displayName":"collab","userId":"14061672705760794442"}},"outputId":"f8e4a32e-1924-4309-d288-376a4c144e1e"},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO flwr 2023-06-25 06:57:06,073 | app.py:146 | Starting Flower simulation, config: ServerConfig(num_rounds=5, round_timeout=None)\n","INFO:flwr:Starting Flower simulation, config: ServerConfig(num_rounds=5, round_timeout=None)\n","2023-06-25 06:57:08,534\tINFO worker.py:1636 -- Started a local Ray instance.\n","INFO flwr 2023-06-25 06:57:09,651 | app.py:180 | Flower VCE: Ray initialized with resources: {'object_store_memory': 26729229926.0, 'CPU': 12.0, 'accelerator_type:A100': 1.0, 'memory': 53458459854.0, 'GPU': 1.0, 'node:172.28.0.12': 1.0}\n","INFO:flwr:Flower VCE: Ray initialized with resources: {'object_store_memory': 26729229926.0, 'CPU': 12.0, 'accelerator_type:A100': 1.0, 'memory': 53458459854.0, 'GPU': 1.0, 'node:172.28.0.12': 1.0}\n","INFO flwr 2023-06-25 06:57:09,653 | server.py:86 | Initializing global parameters\n","INFO:flwr:Initializing global parameters\n","INFO flwr 2023-06-25 06:57:09,655 | server.py:269 | Using initial parameters provided by strategy\n","INFO:flwr:Using initial parameters provided by strategy\n","INFO flwr 2023-06-25 06:57:09,657 | server.py:88 | Evaluating initial parameters\n","INFO:flwr:Evaluating initial parameters\n"]},{"output_type":"stream","name":"stdout","text":["696/696 [==============================] - 2s 3ms/step\n"]},{"output_type":"stream","name":"stderr","text":["INFO flwr 2023-06-25 06:57:14,925 | server.py:91 | initial parameters (loss, other metrics): 1.6153745651245117, {'accuracy': 0.029874213836477988, 'precision': 0.5316927685061484, 'recall': 0.029874213836477988, 'f1-score': 0.019378919018970174}\n","INFO:flwr:initial parameters (loss, other metrics): 1.6153745651245117, {'accuracy': 0.029874213836477988, 'precision': 0.5316927685061484, 'recall': 0.029874213836477988, 'f1-score': 0.019378919018970174}\n","INFO flwr 2023-06-25 06:57:14,927 | server.py:101 | FL starting\n","INFO:flwr:FL starting\n","DEBUG flwr 2023-06-25 06:57:14,930 | server.py:218 | fit_round 1: strategy sampled 4 clients (out of 4)\n","DEBUG:flwr:fit_round 1: strategy sampled 4 clients (out of 4)\n","\u001b[2m\u001b[36m(pid=3044)\u001b[0m 2023-06-25 06:57:16.707078: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[2m\u001b[36m(launch_and_fit pid=3044)\u001b[0m 2023-06-25 06:57:18.293800: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n","DEBUG flwr 2023-06-25 07:02:59,383 | server.py:232 | fit_round 1 received 4 results and 0 failures\n","DEBUG:flwr:fit_round 1 received 4 results and 0 failures\n","WARNING flwr 2023-06-25 07:02:59,414 | fedavg.py:243 | No fit_metrics_aggregation_fn provided\n","WARNING:flwr:No fit_metrics_aggregation_fn provided\n"]},{"output_type":"stream","name":"stdout","text":["696/696 [==============================] - 2s 3ms/step\n"]},{"output_type":"stream","name":"stderr","text":["INFO flwr 2023-06-25 07:03:04,699 | server.py:119 | fit progress: (1, 15.616620063781738, {'accuracy': 0.5149146451033243, 'precision': 0.6579297589424614, 'recall': 0.5149146451033243, 'f1-score': 0.35278709239213984}, 349.76916555599996)\n","INFO:flwr:fit progress: (1, 15.616620063781738, {'accuracy': 0.5149146451033243, 'precision': 0.6579297589424614, 'recall': 0.5149146451033243, 'f1-score': 0.35278709239213984}, 349.76916555599996)\n","DEBUG flwr 2023-06-25 07:03:04,701 | server.py:168 | evaluate_round 1: strategy sampled 4 clients (out of 4)\n","DEBUG:flwr:evaluate_round 1: strategy sampled 4 clients (out of 4)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[2m\u001b[36m(launch_and_evaluate pid=3052)\u001b[0m \r  1/696 [..............................] - ETA: 10:48 - loss: 16.6666 - accuracy: 0.5000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r  4/696 [..............................] - ETA: 14s - loss: 16.6204 - accuracy: 0.4609  \n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3044)\u001b[0m \r  1/696 [..............................] - ETA: 10:46 - loss: 16.6666 - accuracy: 0.5000\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3044)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r  4/696 [..............................] - ETA: 14s - loss: 16.6204 - accuracy: 0.4609  \n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3052)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r  7/696 [..............................] - ETA: 14s - loss: 15.8000 - accuracy: 0.4821\n"," 10/696 [..............................] - ETA: 14s - loss: 15.4749 - accuracy: 0.4969\n"," 25/696 [>.............................] - ETA: 14s - loss: 16.1059 - accuracy: 0.4950\n"," 28/696 [>.............................] - ETA: 14s - loss: 16.0540 - accuracy: 0.4922\n"," 28/696 [>.............................] - ETA: 14s - loss: 16.0540 - accuracy: 0.4922\n"," 48/696 [=>............................] - ETA: 13s - loss: 16.2593 - accuracy: 0.4935\n"," 51/696 [=>............................] - ETA: 13s - loss: 16.0249 - accuracy: 0.4975\n"," 57/696 [=>............................] - ETA: 13s - loss: 15.9272 - accuracy: 0.5016\n"," 72/696 [==>...........................] - ETA: 13s - loss: 16.0033 - accuracy: 0.5004\n"," 73/696 [==>...........................] - ETA: 13s - loss: 15.9131 - accuracy: 0.5026\n"," 75/696 [==>...........................] - ETA: 13s - loss: 15.9196 - accuracy: 0.5021\n"," 94/696 [===>..........................] - ETA: 12s - loss: 15.8357 - accuracy: 0.5063\n"," 96/696 [===>..........................] - ETA: 12s - loss: 15.8324 - accuracy: 0.5072\n"," 97/696 [===>..........................] - ETA: 12s - loss: 15.7920 - accuracy: 0.5074\n","117/696 [====>.........................] - ETA: 12s - loss: 15.5695 - accuracy: 0.5134\n","120/696 [====>.........................] - ETA: 12s - loss: 15.6778 - accuracy: 0.5109\n","124/696 [====>.........................] - ETA: 12s - loss: 15.6763 - accuracy: 0.5113\n","141/696 [=====>........................] - ETA: 11s - loss: 15.6848 - accuracy: 0.5109\n","142/696 [=====>........................] - ETA: 11s - loss: 15.6978 - accuracy: 0.5106\n","147/696 [=====>........................] - ETA: 11s - loss: 15.6289 - accuracy: 0.5130\n","163/696 [======>.......................] - ETA: 11s - loss: 15.5581 - accuracy: 0.5138\n","165/696 [======>.......................] - ETA: 11s - loss: 15.5327 - accuracy: 0.5146\n","169/696 [======>.......................] - ETA: 11s - loss: 15.5168 - accuracy: 0.5152\n","186/696 [=======>......................] - ETA: 10s - loss: 15.6419 - accuracy: 0.5143\n","187/696 [=======>......................] - ETA: 10s - loss: 15.6402 - accuracy: 0.5142\n","192/696 [=======>......................] - ETA: 10s - loss: 15.6401 - accuracy: 0.5145\n","210/696 [========>.....................] - ETA: 10s - loss: 15.6939 - accuracy: 0.5141\n","214/696 [========>.....................] - ETA: 10s - loss: 15.7254 - accuracy: 0.5124\n","232/696 [=========>....................] - ETA: 9s - loss: 15.7252 - accuracy: 0.5131 \n","234/696 [=========>....................] - ETA: 9s - loss: 15.6847 - accuracy: 0.5139 \n","235/696 [=========>....................] - ETA: 9s - loss: 15.6834 - accuracy: 0.5138\n","238/696 [=========>....................] - ETA: 9s - loss: 15.6665 - accuracy: 0.5137\n","  4/696 [..............................] - ETA: 13s - loss: 16.6204 - accuracy: 0.4609  \u001b[32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n"," 22/696 [..............................] - ETA: 14s - loss: 15.7592 - accuracy: 0.4929\u001b[32m [repeated 4x across cluster]\u001b[0m\n"," 19/696 [..............................] - ETA: 14s - loss: 16.1368 - accuracy: 0.4852\u001b[32m [repeated 7x across cluster]\u001b[0m\n","256/696 [==========>...................] - ETA: 9s - loss: 15.6426 - accuracy: 0.5143\n"," 25/696 [>.............................] - ETA: 14s - loss: 16.1059 - accuracy: 0.4950\u001b[32m [repeated 2x across cluster]\u001b[0m\n","258/696 [==========>...................] - ETA: 9s - loss: 15.6707 - accuracy: 0.5133\n","262/696 [==========>...................] - ETA: 9s - loss: 15.6611 - accuracy: 0.5134\n"," 43/696 [>.............................] - ETA: 14s - loss: 16.2526 - accuracy: 0.4942\u001b[32m [repeated 8x across cluster]\u001b[0m\n"," 43/696 [>.............................] - ETA: 14s - loss: 16.2526 - accuracy: 0.4942\u001b[32m [repeated 6x across cluster]\u001b[0m\n","280/696 [===========>..................] - ETA: 8s - loss: 15.6841 - accuracy: 0.5127\n"," 49/696 [=>............................] - ETA: 13s - loss: 16.1555 - accuracy: 0.4949\u001b[32m [repeated 3x across cluster]\u001b[0m\n","282/696 [===========>..................] - ETA: 8s - loss: 15.7082 - accuracy: 0.5124\n","283/696 [===========>..................] - ETA: 8s - loss: 15.7009 - accuracy: 0.5126\n"," 67/696 [=>............................] - ETA: 13s - loss: 16.0976 - accuracy: 0.4972\u001b[32m [repeated 9x across cluster]\u001b[0m\n","288/696 [===========>..................] - ETA: 8s - loss: 15.7066 - accuracy: 0.5123\n"," 64/696 [=>............................] - ETA: 13s - loss: 16.0821 - accuracy: 0.5000\u001b[32m [repeated 6x across cluster]\u001b[0m\n","304/696 [============>.................] - ETA: 8s - loss: 15.7628 - accuracy: 0.5108\n"," 88/696 [==>...........................] - ETA: 13s - loss: 15.8935 - accuracy: 0.5050\u001b[32m [repeated 10x across cluster]\u001b[0m\n","306/696 [============>.................] - ETA: 8s - loss: 15.7464 - accuracy: 0.5111\n","307/696 [============>.................] - ETA: 8s - loss: 15.7309 - accuracy: 0.5111\n"," 91/696 [==>...........................] - ETA: 13s - loss: 15.8161 - accuracy: 0.5072\u001b[32m [repeated 5x across cluster]\u001b[0m\n","325/696 [=============>................] - ETA: 8s - loss: 15.7101 - accuracy: 0.5113\n","325/696 [=============>................] - ETA: 8s - loss: 15.7101 - accuracy: 0.5113\n","325/696 [=============>................] - ETA: 8s - loss: 15.7101 - accuracy: 0.5113\n","111/696 [===>..........................] - ETA: 12s - loss: 15.6021 - accuracy: 0.5127\u001b[32m [repeated 7x across cluster]\u001b[0m\n","112/696 [===>..........................] - ETA: 12s - loss: 15.5792 - accuracy: 0.5128\u001b[32m [repeated 9x across cluster]\u001b[0m\n","328/696 [=============>................] - ETA: 7s - loss: 15.7078 - accuracy: 0.5115\n","328/696 [=============>................] - ETA: 7s - loss: 15.7078 - accuracy: 0.5115\n","334/696 [=============>................] - ETA: 7s - loss: 15.7045 - accuracy: 0.5117\n","349/696 [==============>...............] - ETA: 7s - loss: 15.7310 - accuracy: 0.5120\n","118/696 [====>.........................] - ETA: 12s - loss: 15.6041 - accuracy: 0.5127\u001b[32m [repeated 3x across cluster]\u001b[0m\n","351/696 [==============>...............] - ETA: 7s - loss: 15.7311 - accuracy: 0.5120\n","351/696 [==============>...............] - ETA: 7s - loss: 15.7311 - accuracy: 0.5120\n","139/696 [====>.........................] - ETA: 11s - loss: 15.6490 - accuracy: 0.5117\u001b[32m [repeated 9x across cluster]\u001b[0m\n","139/696 [====>.........................] - ETA: 11s - loss: 15.6490 - accuracy: 0.5117\u001b[32m [repeated 7x across cluster]\u001b[0m\n","372/696 [===============>..............] - ETA: 7s - loss: 15.7634 - accuracy: 0.5110\n","373/696 [===============>..............] - ETA: 6s - loss: 15.7636 - accuracy: 0.5110\n","157/696 [=====>........................] - ETA: 11s - loss: 15.5393 - accuracy: 0.5141\u001b[32m [repeated 7x across cluster]\u001b[0m\n","375/696 [===============>..............] - ETA: 6s - loss: 15.7699 - accuracy: 0.5112\n","375/696 [===============>..............] - ETA: 6s - loss: 15.7699 - accuracy: 0.5112\n","162/696 [=====>........................] - ETA: 11s - loss: 15.5691 - accuracy: 0.5133\u001b[32m [repeated 7x across cluster]\u001b[0m\n","163/696 [======>.......................] - ETA: 11s - loss: 15.5581 - accuracy: 0.5138\u001b[32m [repeated 2x across cluster]\u001b[0m\n","396/696 [================>.............] - ETA: 6s - loss: 15.7420 - accuracy: 0.5122\n","181/696 [======>.......................] - ETA: 11s - loss: 15.6223 - accuracy: 0.5138\u001b[32m [repeated 5x across cluster]\u001b[0m\n","184/696 [======>.......................] - ETA: 10s - loss: 15.6292 - accuracy: 0.5138\u001b[32m [repeated 9x across cluster]\u001b[0m\n","399/696 [================>.............] - ETA: 6s - loss: 15.7595 - accuracy: 0.5122\n","399/696 [================>.............] - ETA: 6s - loss: 15.7595 - accuracy: 0.5122\n","415/696 [================>.............] - ETA: 6s - loss: 15.7578 - accuracy: 0.5121\n","207/696 [=======>......................] - ETA: 10s - loss: 15.6977 - accuracy: 0.5139\u001b[32m [repeated 7x across cluster]\u001b[0m\n","420/696 [=================>............] - ETA: 5s - loss: 15.7454 - accuracy: 0.5122\n","421/696 [=================>............] - ETA: 5s - loss: 15.7425 - accuracy: 0.5123\n","208/696 [=======>......................] - ETA: 10s - loss: 15.6943 - accuracy: 0.5141\u001b[32m [repeated 10x across cluster]\u001b[0m\n","423/696 [=================>............] - ETA: 5s - loss: 15.7275 - accuracy: 0.5128\n","226/696 [========>.....................] - ETA: 10s - loss: 15.7018 - accuracy: 0.5131\u001b[32m [repeated 7x across cluster]\u001b[0m\n","444/696 [==================>...........] - ETA: 5s - loss: 15.7324 - accuracy: 0.5125\n","442/696 [==================>...........] - ETA: 5s - loss: 15.7335 - accuracy: 0.5123\n","445/696 [==================>...........] - ETA: 5s - loss: 15.7333 - accuracy: 0.5124\n","231/696 [========>.....................] - ETA: 10s - loss: 15.7349 - accuracy: 0.5123\u001b[32m [repeated 8x across cluster]\u001b[0m\n","232/696 [=========>....................] - ETA: 9s - loss: 15.7252 - accuracy: 0.5131 \u001b[32m [repeated 2x across cluster]\u001b[0m\n","465/696 [===================>..........] - ETA: 5s - loss: 15.7282 - accuracy: 0.5122\n","255/696 [=========>....................] - ETA: 9s - loss: 15.6444 - accuracy: 0.5142\u001b[32m [repeated 8x across cluster]\u001b[0m\n","468/696 [===================>..........] - ETA: 4s - loss: 15.7435 - accuracy: 0.5121\n","468/696 [===================>..........] - ETA: 4s - loss: 15.7435 - accuracy: 0.5121\n","250/696 [=========>....................] - ETA: 9s - loss: 15.6288 - accuracy: 0.5149\u001b[32m [repeated 7x across cluster]\u001b[0m\n","474/696 [===================>..........] - ETA: 4s - loss: 15.7256 - accuracy: 0.5123\n","256/696 [==========>...................] - ETA: 9s - loss: 15.6426 - accuracy: 0.5143\u001b[32m [repeated 2x across cluster]\u001b[0m\n","489/696 [====================>.........] - ETA: 4s - loss: 15.6896 - accuracy: 0.5132\n","489/696 [====================>.........] - ETA: 4s - loss: 15.6896 - accuracy: 0.5132\n","276/696 [==========>...................] - ETA: 9s - loss: 15.6778 - accuracy: 0.5129\u001b[32m [repeated 8x across cluster]\u001b[0m\n","492/696 [====================>.........] - ETA: 4s - loss: 15.6927 - accuracy: 0.5130\n","274/696 [==========>...................] - ETA: 9s - loss: 15.6674 - accuracy: 0.5132\u001b[32m [repeated 7x across cluster]\u001b[0m\n","496/696 [====================>.........] - ETA: 4s - loss: 15.6770 - accuracy: 0.5134\n","280/696 [===========>..................] - ETA: 8s - loss: 15.6841 - accuracy: 0.5127\u001b[32m [repeated 2x across cluster]\u001b[0m\n","512/696 [=====================>........] - ETA: 4s - loss: 15.6795 - accuracy: 0.5134\n","513/696 [=====================>........] - ETA: 3s - loss: 15.6731 - accuracy: 0.5136\n","514/696 [=====================>........] - ETA: 3s - loss: 15.6739 - accuracy: 0.5135\n","298/696 [===========>..................] - ETA: 8s - loss: 15.7624 - accuracy: 0.5115\u001b[32m [repeated 6x across cluster]\u001b[0m\n","300/696 [===========>..................] - ETA: 8s - loss: 15.7859 - accuracy: 0.5106\u001b[32m [repeated 9x across cluster]\u001b[0m\n","304/696 [============>.................] - ETA: 8s - loss: 15.7628 - accuracy: 0.5108\u001b[32m [repeated 2x across cluster]\u001b[0m\n","534/696 [======================>.......] - ETA: 3s - loss: 15.6997 - accuracy: 0.5132\n","537/696 [======================>.......] - ETA: 3s - loss: 15.7003 - accuracy: 0.5128\n","321/696 [============>.................] - ETA: 8s - loss: 15.7314 - accuracy: 0.5110\u001b[32m [repeated 7x across cluster]\u001b[0m\n","322/696 [============>.................] - ETA: 8s - loss: 15.7195 - accuracy: 0.5109\u001b[32m [repeated 7x across cluster]\u001b[0m\n","537/696 [======================>.......] - ETA: 3s - loss: 15.7003 - accuracy: 0.5128\n","345/696 [=============>................] - ETA: 7s - loss: 15.7039 - accuracy: 0.5122\u001b[32m [repeated 6x across cluster]\u001b[0m\n","556/696 [======================>.......] - ETA: 3s - loss: 15.7113 - accuracy: 0.5130\n","343/696 [=============>................] - ETA: 7s - loss: 15.6932 - accuracy: 0.5126\u001b[32m [repeated 7x across cluster]\u001b[0m\n","561/696 [=======================>......] - ETA: 2s - loss: 15.7086 - accuracy: 0.5134\n","558/696 [=======================>......] - ETA: 3s - loss: 15.7217 - accuracy: 0.5129\n","561/696 [=======================>......] - ETA: 2s - loss: 15.7086 - accuracy: 0.5134\n","349/696 [==============>...............] - ETA: 7s - loss: 15.7310 - accuracy: 0.5120\u001b[32m [repeated 2x across cluster]\u001b[0m\n","580/696 [========================>.....] - ETA: 2s - loss: 15.7079 - accuracy: 0.5134\n","367/696 [==============>...............] - ETA: 7s - loss: 15.7511 - accuracy: 0.5110\u001b[32m [repeated 8x across cluster]\u001b[0m\n","369/696 [==============>...............] - ETA: 7s - loss: 15.7552 - accuracy: 0.5112\u001b[32m [repeated 7x across cluster]\u001b[0m\n","582/696 [========================>.....] - ETA: 2s - loss: 15.7085 - accuracy: 0.5133\n","585/696 [========================>.....] - ETA: 2s - loss: 15.7048 - accuracy: 0.5135\n","583/696 [========================>.....] - ETA: 2s - loss: 15.7023 - accuracy: 0.5135\n","586/696 [========================>.....] - ETA: 2s - loss: 15.7003 - accuracy: 0.5136\n","373/696 [===============>..............] - ETA: 6s - loss: 15.7636 - accuracy: 0.5110\u001b[32m [repeated 2x across cluster]\u001b[0m\n","605/696 [=========================>....] - ETA: 1s - loss: 15.6815 - accuracy: 0.5138\n","391/696 [===============>..............] - ETA: 6s - loss: 15.7643 - accuracy: 0.5111\u001b[32m [repeated 7x across cluster]\u001b[0m\n","393/696 [===============>..............] - ETA: 6s - loss: 15.7553 - accuracy: 0.5117\u001b[32m [repeated 9x across cluster]\u001b[0m\n","604/696 [=========================>....] - ETA: 2s - loss: 15.6937 - accuracy: 0.5136\n","609/696 [=========================>....] - ETA: 1s - loss: 15.6780 - accuracy: 0.5138\n","397/696 [================>.............] - ETA: 6s - loss: 15.7566 - accuracy: 0.5119\u001b[32m [repeated 2x across cluster]\u001b[0m\n","415/696 [================>.............] - ETA: 6s - loss: 15.7578 - accuracy: 0.5121\u001b[32m [repeated 6x across cluster]\u001b[0m\n","417/696 [================>.............] - ETA: 6s - loss: 15.7579 - accuracy: 0.5121\u001b[32m [repeated 11x across cluster]\u001b[0m\n","627/696 [==========================>...] - ETA: 1s - loss: 15.7055 - accuracy: 0.5135\n","630/696 [==========================>...] - ETA: 1s - loss: 15.6896 - accuracy: 0.5135\n","632/696 [==========================>...] - ETA: 1s - loss: 15.6811 - accuracy: 0.5137\n","438/696 [=================>............] - ETA: 5s - loss: 15.7379 - accuracy: 0.5121\u001b[32m [repeated 10x across cluster]\u001b[0m\n","440/696 [=================>............] - ETA: 5s - loss: 15.7349 - accuracy: 0.5123\u001b[32m [repeated 7x across cluster]\u001b[0m\n","651/696 [===========================>..] - ETA: 0s - loss: 15.6489 - accuracy: 0.5148\n","650/696 [===========================>..] - ETA: 1s - loss: 15.6549 - accuracy: 0.5146\n","653/696 [===========================>..] - ETA: 0s - loss: 15.6479 - accuracy: 0.5147\n","653/696 [===========================>..] - ETA: 0s - loss: 15.6479 - accuracy: 0.5147\n","461/696 [==================>...........] - ETA: 5s - loss: 15.7291 - accuracy: 0.5121\u001b[32m [repeated 8x across cluster]\u001b[0m\n","462/696 [==================>...........] - ETA: 5s - loss: 15.7192 - accuracy: 0.5122\u001b[32m [repeated 9x across cluster]\u001b[0m\n","674/696 [============================>.] - ETA: 0s - loss: 15.6474 - accuracy: 0.5145\n","676/696 [============================>.] - ETA: 0s - loss: 15.6402 - accuracy: 0.5147\n","674/696 [============================>.] - ETA: 0s - loss: 15.6474 - accuracy: 0.5145\n"]},{"output_type":"stream","name":"stderr","text":["DEBUG flwr 2023-06-25 07:03:22,374 | server.py:182 | evaluate_round 1 received 4 results and 0 failures\n","DEBUG:flwr:evaluate_round 1 received 4 results and 0 failures\n","WARNING flwr 2023-06-25 07:03:22,376 | fedavg.py:274 | No evaluate_metrics_aggregation_fn provided\n","WARNING:flwr:No evaluate_metrics_aggregation_fn provided\n","DEBUG flwr 2023-06-25 07:03:22,379 | server.py:218 | fit_round 2: strategy sampled 4 clients (out of 4)\n","DEBUG:flwr:fit_round 2: strategy sampled 4 clients (out of 4)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[2m\u001b[36m(launch_and_evaluate pid=3052)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r463/696 [==================>...........] - ETA: 5s - loss: 15.7235 - accuracy: 0.5122\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r466/696 [===================>..........] - ETA: 5s - loss: 15.7416 - accuracy: 0.5119\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3041)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r480/696 [===================>..........] - ETA: 4s - loss: 15.7085 - accuracy: 0.5125\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r483/696 [===================>..........] - ETA: 4s - loss: 15.6813 - accuracy: 0.5135\u001b[32m [repeated 6x across cluster]\u001b[0m\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3041)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r486/696 [===================>..........] - ETA: 4s - loss: 15.6964 - accuracy: 0.5131\u001b[32m [repeated 9x across cluster]\u001b[0m\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3041)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r695/696 [============================>.] - ETA: 0s - loss: 15.6204 - accuracy: 0.5153\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r696/696 [==============================] - 16s 22ms/step - loss: 15.6166 - accuracy: 0.5154\n","696/696 [==============================] - 16s 22ms/step - loss: 15.6166 - accuracy: 0.5154\n","696/696 [==============================] - 16s 22ms/step - loss: 15.6166 - accuracy: 0.5154\n"]},{"output_type":"stream","name":"stderr","text":["DEBUG flwr 2023-06-25 07:09:02,149 | server.py:232 | fit_round 2 received 4 results and 0 failures\n","DEBUG:flwr:fit_round 2 received 4 results and 0 failures\n"]},{"output_type":"stream","name":"stdout","text":["696/696 [==============================] - 2s 3ms/step\n"]},{"output_type":"stream","name":"stderr","text":["INFO flwr 2023-06-25 07:09:07,170 | server.py:119 | fit progress: (2, 0.14071901142597198, {'accuracy': 0.9530098831985624, 'precision': 0.9533867020479112, 'recall': 0.9530098831985624, 'f1-score': 0.9496820899686648}, 712.240522027)\n","INFO:flwr:fit progress: (2, 0.14071901142597198, {'accuracy': 0.9530098831985624, 'precision': 0.9533867020479112, 'recall': 0.9530098831985624, 'f1-score': 0.9496820899686648}, 712.240522027)\n","DEBUG flwr 2023-06-25 07:09:07,173 | server.py:168 | evaluate_round 2: strategy sampled 4 clients (out of 4)\n","DEBUG:flwr:evaluate_round 2: strategy sampled 4 clients (out of 4)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[2m\u001b[36m(launch_and_evaluate pid=3044)\u001b[0m \r  1/696 [..............................] - ETA: 9:49 - loss: 0.0973 - accuracy: 0.9688\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3052)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r487/696 [===================>..........] - ETA: 4s - loss: 15.6938 - accuracy: 0.5132\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r490/696 [====================>.........] - ETA: 4s - loss: 15.6880 - accuracy: 0.5131\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3052)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r510/696 [====================>.........] - ETA: 4s - loss: 15.6626 - accuracy: 0.5137\u001b[32m [repeated 9x across cluster]\u001b[0m\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3041)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r504/696 [====================>.........] - ETA: 4s - loss: 15.6641 - accuracy: 0.5136\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r507/696 [====================>.........] - ETA: 4s - loss: 15.6575 - accuracy: 0.5139\u001b[32m [repeated 7x across cluster]\u001b[0m\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3044)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r532/696 [=====================>........] - ETA: 3s - loss: 15.6934 - accuracy: 0.5132\u001b[32m [repeated 8x across cluster]\u001b[0m\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3041)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r528/696 [=====================>........] - ETA: 3s - loss: 15.6856 - accuracy: 0.5132\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r531/696 [=====================>........] - ETA: 3s - loss: 15.6971 - accuracy: 0.5132\u001b[32m [repeated 8x across cluster]\u001b[0m\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3053)\u001b[0m \r  1/696 [..............................] - ETA: 9:49 - loss: 0.0973 - accuracy: 0.9688\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3041)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r552/696 [======================>.......] - ETA: 3s - loss: 15.7213 - accuracy: 0.5127\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r555/696 [======================>.......] - ETA: 3s - loss: 15.7065 - accuracy: 0.5128\u001b[32m [repeated 9x across cluster]\u001b[0m\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3052)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r555/696 [======================>.......] - ETA: 3s - loss: 15.7065 - accuracy: 0.5128\u001b[32m [repeated 8x across cluster]\u001b[0m\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3041)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r576/696 [=======================>......] - ETA: 2s - loss: 15.7127 - accuracy: 0.5131\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r579/696 [=======================>......] - ETA: 2s - loss: 15.7082 - accuracy: 0.5134\u001b[32m [repeated 10x across cluster]\u001b[0m\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3053)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r578/696 [=======================>......] - ETA: 2s - loss: 15.7190 - accuracy: 0.5131\u001b[32m [repeated 6x across cluster]\u001b[0m\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3041)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r603/696 [========================>.....] - ETA: 2s - loss: 15.6922 - accuracy: 0.5135\u001b[32m [repeated 6x across cluster]\u001b[0m\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3052)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r597/696 [========================>.....] - ETA: 2s - loss: 15.6790 - accuracy: 0.5141\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r600/696 [========================>.....] - ETA: 2s - loss: 15.6793 - accuracy: 0.5142\u001b[32m [repeated 9x across cluster]\u001b[0m\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3052)\u001b[0m \r  1/696 [..............................] - ETA: 9:49 - loss: 0.0973 - accuracy: 0.9688\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3052)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r623/696 [=========================>....] - ETA: 1s - loss: 15.7057 - accuracy: 0.5133\u001b[32m [repeated 11x across cluster]\u001b[0m\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3044)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r621/696 [=========================>....] - ETA: 1s - loss: 15.6937 - accuracy: 0.5137\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r624/696 [=========================>....] - ETA: 1s - loss: 15.7110 - accuracy: 0.5132\u001b[32m [repeated 6x across cluster]\u001b[0m\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3052)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r626/696 [=========================>....] - ETA: 1s - loss: 15.7050 - accuracy: 0.5134\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r629/696 [==========================>...] - ETA: 1s - loss: 15.6910 - accuracy: 0.5136\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3052)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r644/696 [==========================>...] - ETA: 1s - loss: 15.6553 - accuracy: 0.5145\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r647/696 [==========================>...] - ETA: 1s - loss: 15.6451 - accuracy: 0.5148\u001b[32m [repeated 8x across cluster]\u001b[0m\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3041)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r645/696 [==========================>...] - ETA: 1s - loss: 15.6525 - accuracy: 0.5145\u001b[32m [repeated 7x across cluster]\u001b[0m\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3044)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r669/696 [===========================>..] - ETA: 0s - loss: 15.6615 - accuracy: 0.5144\u001b[32m [repeated 9x across cluster]\u001b[0m\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3052)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r668/696 [===========================>..] - ETA: 0s - loss: 15.6589 - accuracy: 0.5144\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r671/696 [===========================>..] - ETA: 0s - loss: 15.6634 - accuracy: 0.5141\u001b[32m [repeated 8x across cluster]\u001b[0m\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3044)\u001b[0m \r  1/696 [..............................] - ETA: 9:49 - loss: 0.0973 - accuracy: 0.9688\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3052)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r692/696 [============================>.] - ETA: 0s - loss: 15.6244 - accuracy: 0.5153\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r695/696 [============================>.] - ETA: 0s - loss: 15.6204 - accuracy: 0.5153\u001b[32m [repeated 10x across cluster]\u001b[0m\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3053)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r693/696 [============================>.] - ETA: 0s - loss: 15.6183 - accuracy: 0.5154\u001b[32m [repeated 6x across cluster]\u001b[0m\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3052)\u001b[0m \r  1/696 [..............................] - ETA: 9:49 - loss: 0.0973 - accuracy: 0.9688\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3044)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r  4/696 [..............................] - ETA: 13s - loss: 0.0735 - accuracy: 0.9766 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r  7/696 [..............................] - ETA: 13s - loss: 0.0651 - accuracy: 0.9777\n","  4/696 [..............................] - ETA: 15s - loss: 0.0735 - accuracy: 0.9766  \n"," 13/696 [..............................] - ETA: 14s - loss: 0.0760 - accuracy: 0.9736\n","  4/696 [..............................] - ETA: 15s - loss: 0.0735 - accuracy: 0.9766  \n","  7/696 [..............................] - ETA: 15s - loss: 0.0651 - accuracy: 0.9777\n"," 10/696 [..............................] - ETA: 15s - loss: 0.0716 - accuracy: 0.9781\n"," 28/696 [>.............................] - ETA: 14s - loss: 0.1404 - accuracy: 0.9542\n"," 31/696 [>.............................] - ETA: 14s - loss: 0.1401 - accuracy: 0.9516\n"," 25/696 [>.............................] - ETA: 14s - loss: 0.1445 - accuracy: 0.9525\n"," 52/696 [=>............................] - ETA: 14s - loss: 0.1396 - accuracy: 0.9519\n"," 55/696 [=>............................] - ETA: 13s - loss: 0.1423 - accuracy: 0.9506\n"," 49/696 [=>............................] - ETA: 14s - loss: 0.1378 - accuracy: 0.9522\n"," 75/696 [==>...........................] - ETA: 13s - loss: 0.1422 - accuracy: 0.9479\n"," 72/696 [==>...........................] - ETA: 13s - loss: 0.1428 - accuracy: 0.9479\n"," 70/696 [==>...........................] - ETA: 13s - loss: 0.1418 - accuracy: 0.9482\n"," 93/696 [===>..........................] - ETA: 13s - loss: 0.1355 - accuracy: 0.9526\n"," 99/696 [===>..........................] - ETA: 13s - loss: 0.1371 - accuracy: 0.9517\n","117/696 [====>.........................] - ETA: 12s - loss: 0.1343 - accuracy: 0.9530\n","123/696 [====>.........................] - ETA: 12s - loss: 0.1328 - accuracy: 0.9533\n","141/696 [=====>........................] - ETA: 12s - loss: 0.1377 - accuracy: 0.9526\n","147/696 [=====>........................] - ETA: 12s - loss: 0.1361 - accuracy: 0.9534\n","165/696 [======>.......................] - ETA: 11s - loss: 0.1342 - accuracy: 0.9544\n","163/696 [======>.......................] - ETA: 11s - loss: 0.1327 - accuracy: 0.9548\n","171/696 [======>.......................] - ETA: 11s - loss: 0.1339 - accuracy: 0.9549\n","186/696 [=======>......................] - ETA: 11s - loss: 0.1406 - accuracy: 0.9535\n","189/696 [=======>......................] - ETA: 11s - loss: 0.1404 - accuracy: 0.9534\n","195/696 [=======>......................] - ETA: 11s - loss: 0.1403 - accuracy: 0.9534\n","201/696 [=======>......................] - ETA: 10s - loss: 0.1387 - accuracy: 0.9537\n","210/696 [========>.....................] - ETA: 10s - loss: 0.1390 - accuracy: 0.9537\n","213/696 [========>.....................] - ETA: 10s - loss: 0.1376 - accuracy: 0.9541\n","216/696 [========>.....................] - ETA: 10s - loss: 0.1377 - accuracy: 0.9540\n","219/696 [========>.....................] - ETA: 10s - loss: 0.1369 - accuracy: 0.9543\n","225/696 [========>.....................] - ETA: 10s - loss: 0.1352 - accuracy: 0.9549\n","234/696 [=========>....................] - ETA: 10s - loss: 0.1335 - accuracy: 0.9553\n","234/696 [=========>....................] - ETA: 10s - loss: 0.1335 - accuracy: 0.9553\n","228/696 [========>.....................] - ETA: 10s - loss: 0.1343 - accuracy: 0.9552\n","237/696 [=========>....................] - ETA: 10s - loss: 0.1357 - accuracy: 0.9546\n","235/696 [=========>....................] - ETA: 10s - loss: 0.1347 - accuracy: 0.9551\n"," 19/696 [..............................] - ETA: 15s - loss: 0.1137 - accuracy: 0.9589\u001b[32m [repeated 5x across cluster]\u001b[0m\n"," 22/696 [..............................] - ETA: 14s - loss: 0.1118 - accuracy: 0.9560\u001b[32m [repeated 8x across cluster]\u001b[0m\n","249/696 [=========>....................] - ETA: 9s - loss: 0.1358 - accuracy: 0.9542\n","252/696 [=========>....................] - ETA: 9s - loss: 0.1359 - accuracy: 0.9541\n","258/696 [==========>...................] - ETA: 9s - loss: 0.1358 - accuracy: 0.9542\n"," 43/696 [>.............................] - ETA: 14s - loss: 0.1307 - accuracy: 0.9557\u001b[32m [repeated 10x across cluster]\u001b[0m\n","252/696 [=========>....................] - ETA: 9s - loss: 0.1359 - accuracy: 0.9541\n","261/696 [==========>...................] - ETA: 9s - loss: 0.1355 - accuracy: 0.9544\n"," 46/696 [>.............................] - ETA: 14s - loss: 0.1328 - accuracy: 0.9552\u001b[32m [repeated 7x across cluster]\u001b[0m\n","267/696 [==========>...................] - ETA: 9s - loss: 0.1373 - accuracy: 0.9542\n","282/696 [===========>..................] - ETA: 9s - loss: 0.1351 - accuracy: 0.9548\n"," 67/696 [=>............................] - ETA: 13s - loss: 0.1360 - accuracy: 0.9506\u001b[32m [repeated 9x across cluster]\u001b[0m\n","285/696 [===========>..................] - ETA: 9s - loss: 0.1355 - accuracy: 0.9549\n"," 61/696 [=>............................] - ETA: 14s - loss: 0.1421 - accuracy: 0.9498\u001b[32m [repeated 7x across cluster]\u001b[0m\n","291/696 [===========>..................] - ETA: 8s - loss: 0.1367 - accuracy: 0.9546\n","306/696 [============>.................] - ETA: 8s - loss: 0.1391 - accuracy: 0.9538\n"," 91/696 [==>...........................] - ETA: 13s - loss: 0.1377 - accuracy: 0.9519\u001b[32m [repeated 9x across cluster]\u001b[0m\n"," 91/696 [==>...........................] - ETA: 13s - loss: 0.1377 - accuracy: 0.9519\u001b[32m [repeated 8x across cluster]\u001b[0m\n","309/696 [============>.................] - ETA: 8s - loss: 0.1387 - accuracy: 0.9540\n","303/696 [============>.................] - ETA: 8s - loss: 0.1393 - accuracy: 0.9539\n","315/696 [============>.................] - ETA: 8s - loss: 0.1381 - accuracy: 0.9541\n","115/696 [===>..........................] - ETA: 12s - loss: 0.1346 - accuracy: 0.9527\u001b[32m [repeated 9x across cluster]\u001b[0m\n","115/696 [===>..........................] - ETA: 12s - loss: 0.1346 - accuracy: 0.9527\u001b[32m [repeated 10x across cluster]\u001b[0m\n","327/696 [=============>................] - ETA: 8s - loss: 0.1377 - accuracy: 0.9540\n","333/696 [=============>................] - ETA: 8s - loss: 0.1390 - accuracy: 0.9541\n","326/696 [=============>................] - ETA: 8s - loss: 0.1381 - accuracy: 0.9540\n","139/696 [====>.........................] - ETA: 12s - loss: 0.1385 - accuracy: 0.9523\u001b[32m [repeated 9x across cluster]\u001b[0m\n","348/696 [==============>...............] - ETA: 7s - loss: 0.1391 - accuracy: 0.9541\n","139/696 [====>.........................] - ETA: 12s - loss: 0.1385 - accuracy: 0.9523\u001b[32m [repeated 10x across cluster]\u001b[0m\n","351/696 [==============>...............] - ETA: 7s - loss: 0.1388 - accuracy: 0.9542\n","357/696 [==============>...............] - ETA: 7s - loss: 0.1388 - accuracy: 0.9541\n","162/696 [=====>........................] - ETA: 11s - loss: 0.1315 - accuracy: 0.9549\u001b[32m [repeated 8x across cluster]\u001b[0m\n","372/696 [===============>..............] - ETA: 7s - loss: 0.1382 - accuracy: 0.9540\n","160/696 [=====>........................] - ETA: 11s - loss: 0.1325 - accuracy: 0.9545\u001b[32m [repeated 9x across cluster]\u001b[0m\n","378/696 [===============>..............] - ETA: 7s - loss: 0.1400 - accuracy: 0.9534\n","381/696 [===============>..............] - ETA: 6s - loss: 0.1404 - accuracy: 0.9534\n","387/696 [===============>..............] - ETA: 6s - loss: 0.1398 - accuracy: 0.9536\n","181/696 [======>.......................] - ETA: 11s - loss: 0.1394 - accuracy: 0.9537\u001b[32m [repeated 9x across cluster]\u001b[0m\n","396/696 [================>.............] - ETA: 6s - loss: 0.1404 - accuracy: 0.9530\n","184/696 [======>.......................] - ETA: 11s - loss: 0.1397 - accuracy: 0.9538\u001b[32m [repeated 7x across cluster]\u001b[0m\n","402/696 [================>.............] - ETA: 6s - loss: 0.1418 - accuracy: 0.9528\n","395/696 [================>.............] - ETA: 6s - loss: 0.1405 - accuracy: 0.9530\n","408/696 [================>.............] - ETA: 6s - loss: 0.1426 - accuracy: 0.9524\n","187/696 [=======>......................] - ETA: 11s - loss: 0.1405 - accuracy: 0.9534\u001b[32m [repeated 2x across cluster]\u001b[0m\n","204/696 [=======>......................] - ETA: 10s - loss: 0.1386 - accuracy: 0.9537\u001b[32m [repeated 7x across cluster]\u001b[0m\n","423/696 [=================>............] - ETA: 6s - loss: 0.1420 - accuracy: 0.9527\n","418/696 [=================>............] - ETA: 6s - loss: 0.1411 - accuracy: 0.9530\n","208/696 [=======>......................] - ETA: 10s - loss: 0.1379 - accuracy: 0.9540\u001b[32m [repeated 7x across cluster]\u001b[0m\n","426/696 [=================>............] - ETA: 5s - loss: 0.1419 - accuracy: 0.9525\n","432/696 [=================>............] - ETA: 5s - loss: 0.1424 - accuracy: 0.9527\n","441/696 [==================>...........] - ETA: 5s - loss: 0.1422 - accuracy: 0.9527\n","211/696 [========>.....................] - ETA: 10s - loss: 0.1385 - accuracy: 0.9539\u001b[32m [repeated 2x across cluster]\u001b[0m\n","447/696 [==================>...........] - ETA: 5s - loss: 0.1420 - accuracy: 0.9527\n","229/696 [========>.....................] - ETA: 10s - loss: 0.1338 - accuracy: 0.9554\u001b[32m [repeated 8x across cluster]\u001b[0m\n","442/696 [==================>...........] - ETA: 5s - loss: 0.1419 - accuracy: 0.9528\n","453/696 [==================>...........] - ETA: 5s - loss: 0.1422 - accuracy: 0.9526\n","229/696 [========>.....................] - ETA: 10s - loss: 0.1338 - accuracy: 0.9554\u001b[32m [repeated 6x across cluster]\u001b[0m\n","468/696 [===================>..........] - ETA: 4s - loss: 0.1426 - accuracy: 0.9523\n","468/696 [===================>..........] - ETA: 4s - loss: 0.1426 - accuracy: 0.9523\n","471/696 [===================>..........] - ETA: 4s - loss: 0.1421 - accuracy: 0.9524\n","247/696 [=========>....................] - ETA: 9s - loss: 0.1358 - accuracy: 0.9545 \u001b[32m [repeated 5x across cluster]\u001b[0m\n","244/696 [=========>....................] - ETA: 10s - loss: 0.1348 - accuracy: 0.9547\u001b[32m [repeated 5x across cluster]\u001b[0m\n","464/696 [===================>..........] - ETA: 5s - loss: 0.1421 - accuracy: 0.9523\n","477/696 [===================>..........] - ETA: 4s - loss: 0.1427 - accuracy: 0.9526\n","483/696 [===================>..........] - ETA: 4s - loss: 0.1418 - accuracy: 0.9528\n","253/696 [=========>....................] - ETA: 9s - loss: 0.1354 - accuracy: 0.9543\u001b[32m [repeated 2x across cluster]\u001b[0m\n","492/696 [====================>.........] - ETA: 4s - loss: 0.1411 - accuracy: 0.9529\n","492/696 [====================>.........] - ETA: 4s - loss: 0.1411 - accuracy: 0.9529\n","498/696 [====================>.........] - ETA: 4s - loss: 0.1411 - accuracy: 0.9530\n","277/696 [==========>...................] - ETA: 9s - loss: 0.1361 - accuracy: 0.9545\u001b[32m [repeated 8x across cluster]\u001b[0m\n","488/696 [====================>.........] - ETA: 4s - loss: 0.1419 - accuracy: 0.9527\n","277/696 [==========>...................] - ETA: 9s - loss: 0.1361 - accuracy: 0.9545\u001b[32m [repeated 9x across cluster]\u001b[0m\n","513/696 [=====================>........] - ETA: 4s - loss: 0.1412 - accuracy: 0.9529\n","516/696 [=====================>........] - ETA: 3s - loss: 0.1414 - accuracy: 0.9527\n","301/696 [===========>..................] - ETA: 8s - loss: 0.1391 - accuracy: 0.9539\u001b[32m [repeated 9x across cluster]\u001b[0m\n","522/696 [=====================>........] - ETA: 3s - loss: 0.1410 - accuracy: 0.9528\n","295/696 [===========>..................] - ETA: 8s - loss: 0.1368 - accuracy: 0.9542\u001b[32m [repeated 8x across cluster]\u001b[0m\n","537/696 [======================>.......] - ETA: 3s - loss: 0.1400 - accuracy: 0.9531\n","543/696 [======================>.......] - ETA: 3s - loss: 0.1398 - accuracy: 0.9532\n","319/696 [============>.................] - ETA: 8s - loss: 0.1381 - accuracy: 0.9542\u001b[32m [repeated 6x across cluster]\u001b[0m\n","535/696 [======================>.......] - ETA: 3s - loss: 0.1401 - accuracy: 0.9532\n","322/696 [============>.................] - ETA: 8s - loss: 0.1380 - accuracy: 0.9539\u001b[32m [repeated 10x across cluster]\u001b[0m\n","558/696 [=======================>......] - ETA: 3s - loss: 0.1390 - accuracy: 0.9535\n","561/696 [=======================>......] - ETA: 2s - loss: 0.1386 - accuracy: 0.9537\n","567/696 [=======================>......] - ETA: 2s - loss: 0.1402 - accuracy: 0.9532\n","346/696 [=============>................] - ETA: 7s - loss: 0.1396 - accuracy: 0.9540\u001b[32m [repeated 9x across cluster]\u001b[0m\n","343/696 [=============>................] - ETA: 7s - loss: 0.1401 - accuracy: 0.9539\u001b[32m [repeated 7x across cluster]\u001b[0m\n","570/696 [=======================>......] - ETA: 2s - loss: 0.1401 - accuracy: 0.9532\n","582/696 [========================>.....] - ETA: 2s - loss: 0.1405 - accuracy: 0.9531\n","585/696 [========================>.....] - ETA: 2s - loss: 0.1407 - accuracy: 0.9530\n","349/696 [==============>...............] - ETA: 7s - loss: 0.1393 - accuracy: 0.9541\u001b[32m [repeated 2x across cluster]\u001b[0m\n","591/696 [========================>.....] - ETA: 2s - loss: 0.1406 - accuracy: 0.9532\n","361/696 [==============>...............] - ETA: 7s - loss: 0.1395 - accuracy: 0.9540\u001b[32m [repeated 6x across cluster]\u001b[0m\n","370/696 [==============>...............] - ETA: 7s - loss: 0.1384 - accuracy: 0.9541\u001b[32m [repeated 9x across cluster]\u001b[0m\n","606/696 [=========================>....] - ETA: 1s - loss: 0.1399 - accuracy: 0.9532\n","612/696 [=========================>....] - ETA: 1s - loss: 0.1405 - accuracy: 0.9531\n","612/696 [=========================>....] - ETA: 1s - loss: 0.1405 - accuracy: 0.9531\n","615/696 [=========================>....] - ETA: 1s - loss: 0.1410 - accuracy: 0.9530\n","394/696 [===============>..............] - ETA: 6s - loss: 0.1407 - accuracy: 0.9530\u001b[32m [repeated 8x across cluster]\u001b[0m\n","391/696 [===============>..............] - ETA: 6s - loss: 0.1400 - accuracy: 0.9532\u001b[32m [repeated 6x across cluster]\u001b[0m\n","627/696 [==========================>...] - ETA: 1s - loss: 0.1408 - accuracy: 0.9530\n","630/696 [==========================>...] - ETA: 1s - loss: 0.1405 - accuracy: 0.9530\n","636/696 [==========================>...] - ETA: 1s - loss: 0.1408 - accuracy: 0.9529\n","416/696 [================>.............] - ETA: 6s - loss: 0.1415 - accuracy: 0.9529\u001b[32m [repeated 7x across cluster]\u001b[0m\n","412/696 [================>.............] - ETA: 6s - loss: 0.1425 - accuracy: 0.9526\u001b[32m [repeated 7x across cluster]\u001b[0m\n","642/696 [==========================>...] - ETA: 1s - loss: 0.1404 - accuracy: 0.9529\n","651/696 [===========================>..] - ETA: 0s - loss: 0.1402 - accuracy: 0.9529\n","657/696 [===========================>..] - ETA: 0s - loss: 0.1401 - accuracy: 0.9530\n","652/696 [===========================>..] - ETA: 0s - loss: 0.1400 - accuracy: 0.9530\n","660/696 [===========================>..] - ETA: 0s - loss: 0.1401 - accuracy: 0.9529\n","439/696 [=================>............] - ETA: 5s - loss: 0.1421 - accuracy: 0.9527\u001b[32m [repeated 9x across cluster]\u001b[0m\n","660/696 [===========================>..] - ETA: 0s - loss: 0.1401 - accuracy: 0.9529\n","436/696 [=================>............] - ETA: 5s - loss: 0.1425 - accuracy: 0.9526\u001b[32m [repeated 5x across cluster]\u001b[0m\n","678/696 [============================>.] - ETA: 0s - loss: 0.1408 - accuracy: 0.9530\n","681/696 [============================>.] - ETA: 0s - loss: 0.1406 - accuracy: 0.9531\n","460/696 [==================>...........] - ETA: 5s - loss: 0.1417 - accuracy: 0.9525\u001b[32m [repeated 7x across cluster]\u001b[0m\n","673/696 [============================>.] - ETA: 0s - loss: 0.1411 - accuracy: 0.9529\n","463/696 [==================>...........] - ETA: 5s - loss: 0.1422 - accuracy: 0.9523\u001b[32m [repeated 8x across cluster]\u001b[0m\n"]},{"output_type":"stream","name":"stderr","text":["DEBUG flwr 2023-06-25 07:09:24,704 | server.py:182 | evaluate_round 2 received 4 results and 0 failures\n","DEBUG:flwr:evaluate_round 2 received 4 results and 0 failures\n","DEBUG flwr 2023-06-25 07:09:24,707 | server.py:218 | fit_round 3: strategy sampled 4 clients (out of 4)\n","DEBUG:flwr:fit_round 3: strategy sampled 4 clients (out of 4)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[2m\u001b[36m(launch_and_evaluate pid=3044)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r696/696 [==============================] - ETA: 0s - loss: 0.1407 - accuracy: 0.9531\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r696/696 [==============================] - 16s 22ms/step - loss: 0.1407 - accuracy: 0.9531\n","696/696 [==============================] - 16s 22ms/step - loss: 0.1407 - accuracy: 0.9531\n","487/696 [===================>..........] - ETA: 4s - loss: 0.1421 - accuracy: 0.9526\u001b[32m [repeated 10x across cluster]\u001b[0m\n","696/696 [==============================] - 16s 22ms/step - loss: 0.1407 - accuracy: 0.9531\n"]},{"output_type":"stream","name":"stderr","text":["DEBUG flwr 2023-06-25 07:15:05,967 | server.py:232 | fit_round 3 received 4 results and 0 failures\n","DEBUG:flwr:fit_round 3 received 4 results and 0 failures\n"]},{"output_type":"stream","name":"stdout","text":["696/696 [==============================] - 2s 3ms/step\n"]},{"output_type":"stream","name":"stderr","text":["INFO flwr 2023-06-25 07:15:11,405 | server.py:119 | fit progress: (3, 0.16205409169197083, {'accuracy': 0.9649595687331537, 'precision': 0.9668094854590402, 'recall': 0.9649595687331537, 'f1-score': 0.9636704668218635}, 1076.475420693)\n","INFO:flwr:fit progress: (3, 0.16205409169197083, {'accuracy': 0.9649595687331537, 'precision': 0.9668094854590402, 'recall': 0.9649595687331537, 'f1-score': 0.9636704668218635}, 1076.475420693)\n","DEBUG flwr 2023-06-25 07:15:11,407 | server.py:168 | evaluate_round 3: strategy sampled 4 clients (out of 4)\n","DEBUG:flwr:evaluate_round 3: strategy sampled 4 clients (out of 4)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[2m\u001b[36m(launch_and_evaluate pid=3041)\u001b[0m \r  1/696 [..............................] - ETA: 9:32 - loss: 0.0098 - accuracy: 1.0000\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3041)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r487/696 [===================>..........] - ETA: 4s - loss: 0.1421 - accuracy: 0.9526\u001b[32m [repeated 5x across cluster]\u001b[0m\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3053)\u001b[0m \r  1/696 [..............................] - ETA: 9:32 - loss: 0.0098 - accuracy: 1.0000\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3041)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r505/696 [====================>.........] - ETA: 4s - loss: 0.1416 - accuracy: 0.9527\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r508/696 [====================>.........] - ETA: 4s - loss: 0.1418 - accuracy: 0.9527\u001b[32m [repeated 8x across cluster]\u001b[0m\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3053)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r505/696 [====================>.........] - ETA: 4s - loss: 0.1416 - accuracy: 0.9527\u001b[32m [repeated 7x across cluster]\u001b[0m\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3053)\u001b[0m \r  1/696 [..............................] - ETA: 9:32 - loss: 0.0098 - accuracy: 1.0000\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3041)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r532/696 [=====================>........] - ETA: 3s - loss: 0.1407 - accuracy: 0.9529\u001b[32m [repeated 6x across cluster]\u001b[0m\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3052)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r530/696 [=====================>........] - ETA: 3s - loss: 0.1409 - accuracy: 0.9529\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r533/696 [=====================>........] - ETA: 3s - loss: 0.1404 - accuracy: 0.9530\u001b[32m [repeated 10x across cluster]\u001b[0m\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3053)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r553/696 [======================>.......] - ETA: 3s - loss: 0.1394 - accuracy: 0.9534\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r556/696 [======================>.......] - ETA: 3s - loss: 0.1389 - accuracy: 0.9535\u001b[32m [repeated 9x across cluster]\u001b[0m\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3041)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r556/696 [======================>.......] - ETA: 3s - loss: 0.1389 - accuracy: 0.9535\u001b[32m [repeated 7x across cluster]\u001b[0m\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3041)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r571/696 [=======================>......] - ETA: 2s - loss: 0.1399 - accuracy: 0.9533\u001b[32m [repeated 5x across cluster]\u001b[0m\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3041)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r574/696 [=======================>......] - ETA: 2s - loss: 0.1401 - accuracy: 0.9531\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r577/696 [=======================>......] - ETA: 2s - loss: 0.1404 - accuracy: 0.9531\u001b[32m [repeated 10x across cluster]\u001b[0m\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3041)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r601/696 [========================>.....] - ETA: 2s - loss: 0.1397 - accuracy: 0.9532\u001b[32m [repeated 7x across cluster]\u001b[0m\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3052)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r599/696 [========================>.....] - ETA: 2s - loss: 0.1397 - accuracy: 0.9533\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r602/696 [========================>.....] - ETA: 2s - loss: 0.1396 - accuracy: 0.9532\u001b[32m [repeated 10x across cluster]\u001b[0m\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3041)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r619/696 [=========================>....] - ETA: 1s - loss: 0.1408 - accuracy: 0.9530\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r622/696 [=========================>....] - ETA: 1s - loss: 0.1405 - accuracy: 0.9531\u001b[32m [repeated 10x across cluster]\u001b[0m\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3052)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r626/696 [=========================>....] - ETA: 1s - loss: 0.1410 - accuracy: 0.9529\u001b[32m [repeated 5x across cluster]\u001b[0m\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3041)\u001b[0m \r  1/696 [..............................] - ETA: 9:32 - loss: 0.0098 - accuracy: 1.0000\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3041)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r646/696 [==========================>...] - ETA: 1s - loss: 0.1400 - accuracy: 0.9529\u001b[32m [repeated 8x across cluster]\u001b[0m\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3052)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r644/696 [==========================>...] - ETA: 1s - loss: 0.1402 - accuracy: 0.9528\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r647/696 [==========================>...] - ETA: 1s - loss: 0.1398 - accuracy: 0.9530\u001b[32m [repeated 8x across cluster]\u001b[0m\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3052)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r671/696 [===========================>..] - ETA: 0s - loss: 0.1412 - accuracy: 0.9529\u001b[32m [repeated 7x across cluster]\u001b[0m\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3041)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r664/696 [===========================>..] - ETA: 0s - loss: 0.1413 - accuracy: 0.9529\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r667/696 [===========================>..] - ETA: 0s - loss: 0.1412 - accuracy: 0.9528\u001b[32m [repeated 8x across cluster]\u001b[0m\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3041)\u001b[0m \r  1/696 [..............................] - ETA: 9:32 - loss: 0.0098 - accuracy: 1.0000\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3052)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r689/696 [============================>.] - ETA: 0s - loss: 0.1406 - accuracy: 0.9531\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r692/696 [============================>.] - ETA: 0s - loss: 0.1404 - accuracy: 0.9532\u001b[32m [repeated 10x across cluster]\u001b[0m\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3041)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r694/696 [============================>.] - ETA: 0s - loss: 0.1402 - accuracy: 0.9533\u001b[32m [repeated 5x across cluster]\u001b[0m\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3052)\u001b[0m \r  1/696 [..............................] - ETA: 9:32 - loss: 0.0098 - accuracy: 1.0000\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3052)\u001b[0m \r  1/696 [..............................] - ETA: 9:59 - loss: 0.0098 - accuracy: 1.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r  4/696 [..............................] - ETA: 13s - loss: 0.1992 - accuracy: 0.9609 \n","  4/696 [..............................] - ETA: 14s - loss: 0.1992 - accuracy: 0.9609 \n","  4/696 [..............................] - ETA: 14s - loss: 0.1992 - accuracy: 0.9609  \n","  7/696 [..............................] - ETA: 14s - loss: 0.1279 - accuracy: 0.9732\n"," 10/696 [..............................] - ETA: 14s - loss: 0.1002 - accuracy: 0.9781\n","  7/696 [..............................] - ETA: 14s - loss: 0.1279 - accuracy: 0.9732\n"," 25/696 [>.............................] - ETA: 14s - loss: 0.1699 - accuracy: 0.9650\n"," 28/696 [>.............................] - ETA: 14s - loss: 0.1573 - accuracy: 0.9665\n"," 25/696 [>.............................] - ETA: 14s - loss: 0.1699 - accuracy: 0.9650\n"," 49/696 [=>............................] - ETA: 13s - loss: 0.1559 - accuracy: 0.9688\n"," 52/696 [=>............................] - ETA: 13s - loss: 0.1554 - accuracy: 0.9681\n"," 55/696 [=>............................] - ETA: 13s - loss: 0.1686 - accuracy: 0.9670\n"," 70/696 [==>...........................] - ETA: 13s - loss: 0.1914 - accuracy: 0.9643\n"," 73/696 [==>...........................] - ETA: 13s - loss: 0.1874 - accuracy: 0.9645\n"," 73/696 [==>...........................] - ETA: 13s - loss: 0.1874 - accuracy: 0.9645\n"," 94/696 [===>..........................] - ETA: 12s - loss: 0.1902 - accuracy: 0.9648\n"," 97/696 [===>..........................] - ETA: 12s - loss: 0.1860 - accuracy: 0.9649\n"," 94/696 [===>..........................] - ETA: 12s - loss: 0.1902 - accuracy: 0.9648\n","118/696 [====>.........................] - ETA: 12s - loss: 0.1815 - accuracy: 0.9629\n","121/696 [====>.........................] - ETA: 12s - loss: 0.1847 - accuracy: 0.9618\n","124/696 [====>.........................] - ETA: 12s - loss: 0.1805 - accuracy: 0.9627\n","142/696 [=====>........................] - ETA: 11s - loss: 0.1834 - accuracy: 0.9635\n","142/696 [=====>........................] - ETA: 11s - loss: 0.1834 - accuracy: 0.9635\n","148/696 [=====>........................] - ETA: 11s - loss: 0.1810 - accuracy: 0.9639\n","163/696 [======>.......................] - ETA: 11s - loss: 0.1758 - accuracy: 0.9643\n","166/696 [======>.......................] - ETA: 11s - loss: 0.1766 - accuracy: 0.9642\n","172/696 [======>.......................] - ETA: 11s - loss: 0.1753 - accuracy: 0.9648\n","187/696 [=======>......................] - ETA: 10s - loss: 0.1790 - accuracy: 0.9639\n","190/696 [=======>......................] - ETA: 10s - loss: 0.1835 - accuracy: 0.9638\n","190/696 [=======>......................] - ETA: 10s - loss: 0.1835 - accuracy: 0.9638\n","211/696 [========>.....................] - ETA: 10s - loss: 0.1770 - accuracy: 0.9634\n","211/696 [========>.....................] - ETA: 10s - loss: 0.1770 - accuracy: 0.9634\n","217/696 [========>.....................] - ETA: 10s - loss: 0.1760 - accuracy: 0.9639\n","232/696 [=========>....................] - ETA: 9s - loss: 0.1762 - accuracy: 0.9640 \n","  1/696 [..............................] - ETA: 10:12 - loss: 0.0098 - accuracy: 1.0000\u001b[32m [repeated 2x across cluster]\u001b[0m\n","235/696 [=========>....................] - ETA: 9s - loss: 0.1769 - accuracy: 0.9637\n","235/696 [=========>....................] - ETA: 9s - loss: 0.1769 - accuracy: 0.9637 \n","235/696 [=========>....................] - ETA: 9s - loss: 0.1769 - accuracy: 0.9637\n","241/696 [=========>....................] - ETA: 9s - loss: 0.1754 - accuracy: 0.9638\n"," 22/696 [..............................] - ETA: 14s - loss: 0.1273 - accuracy: 0.9673\u001b[32m [repeated 6x across cluster]\u001b[0m\n"," 22/696 [..............................] - ETA: 14s - loss: 0.1273 - accuracy: 0.9673\u001b[32m [repeated 6x across cluster]\u001b[0m\n","256/696 [==========>...................] - ETA: 9s - loss: 0.1751 - accuracy: 0.9641\n","256/696 [==========>...................] - ETA: 9s - loss: 0.1751 - accuracy: 0.9641\n","262/696 [==========>...................] - ETA: 9s - loss: 0.1737 - accuracy: 0.9643\n","259/696 [==========>...................] - ETA: 9s - loss: 0.1750 - accuracy: 0.9643\n"," 46/696 [>.............................] - ETA: 14s - loss: 0.1427 - accuracy: 0.9694\u001b[32m [repeated 9x across cluster]\u001b[0m\n"," 43/696 [>.............................] - ETA: 14s - loss: 0.1474 - accuracy: 0.9688\u001b[32m [repeated 6x across cluster]\u001b[0m\n","280/696 [===========>..................] - ETA: 8s - loss: 0.1714 - accuracy: 0.9646\n","279/696 [===========>..................] - ETA: 9s - loss: 0.1720 - accuracy: 0.9645\n"," 49/696 [=>............................] - ETA: 13s - loss: 0.1559 - accuracy: 0.9688\u001b[32m [repeated 2x across cluster]\u001b[0m\n","283/696 [===========>..................] - ETA: 8s - loss: 0.1696 - accuracy: 0.9650\n"," 67/696 [=>............................] - ETA: 13s - loss: 0.1852 - accuracy: 0.9655\u001b[32m [repeated 8x across cluster]\u001b[0m\n"," 67/696 [=>............................] - ETA: 13s - loss: 0.1852 - accuracy: 0.9655\u001b[32m [repeated 6x across cluster]\u001b[0m\n","297/696 [===========>..................] - ETA: 8s - loss: 0.1719 - accuracy: 0.9650\n","304/696 [============>.................] - ETA: 8s - loss: 0.1719 - accuracy: 0.9649\n"," 91/696 [==>...........................] - ETA: 13s - loss: 0.1956 - accuracy: 0.9643\u001b[32m [repeated 9x across cluster]\u001b[0m\n"," 91/696 [==>...........................] - ETA: 12s - loss: 0.1956 - accuracy: 0.9643\u001b[32m [repeated 7x across cluster]\u001b[0m\n","307/696 [============>.................] - ETA: 8s - loss: 0.1716 - accuracy: 0.9649\n","307/696 [============>.................] - ETA: 8s - loss: 0.1716 - accuracy: 0.9649\n","321/696 [============>.................] - ETA: 8s - loss: 0.1703 - accuracy: 0.9650\n","328/696 [=============>................] - ETA: 7s - loss: 0.1734 - accuracy: 0.9645\n","325/696 [=============>................] - ETA: 8s - loss: 0.1706 - accuracy: 0.9648\n","327/696 [=============>................] - ETA: 8s - loss: 0.1716 - accuracy: 0.9646\n","115/696 [===>..........................] - ETA: 12s - loss: 0.1812 - accuracy: 0.9636\u001b[32m [repeated 9x across cluster]\u001b[0m\n","112/696 [===>..........................] - ETA: 12s - loss: 0.1850 - accuracy: 0.9629\u001b[32m [repeated 6x across cluster]\u001b[0m\n","118/696 [====>.........................] - ETA: 12s - loss: 0.1815 - accuracy: 0.9629\u001b[32m [repeated 2x across cluster]\u001b[0m\n","351/696 [==============>...............] - ETA: 7s - loss: 0.1721 - accuracy: 0.9647\n","349/696 [==============>...............] - ETA: 7s - loss: 0.1729 - accuracy: 0.9646\n","349/696 [==============>...............] - ETA: 7s - loss: 0.1729 - accuracy: 0.9646\n","139/696 [====>.........................] - ETA: 11s - loss: 0.1868 - accuracy: 0.9629\u001b[32m [repeated 7x across cluster]\u001b[0m\n","139/696 [====>.........................] - ETA: 11s - loss: 0.1868 - accuracy: 0.9629\u001b[32m [repeated 9x across cluster]\u001b[0m\n","157/696 [=====>........................] - ETA: 11s - loss: 0.1741 - accuracy: 0.9644\u001b[32m [repeated 7x across cluster]\u001b[0m\n","375/696 [===============>..............] - ETA: 6s - loss: 0.1710 - accuracy: 0.9648\n","373/696 [===============>..............] - ETA: 7s - loss: 0.1717 - accuracy: 0.9648\n","373/696 [===============>..............] - ETA: 7s - loss: 0.1717 - accuracy: 0.9648\n","160/696 [=====>........................] - ETA: 11s - loss: 0.1727 - accuracy: 0.9645\u001b[32m [repeated 7x across cluster]\u001b[0m\n","163/696 [======>.......................] - ETA: 11s - loss: 0.1758 - accuracy: 0.9643\u001b[32m [repeated 2x across cluster]\u001b[0m\n","181/696 [======>.......................] - ETA: 11s - loss: 0.1750 - accuracy: 0.9639\u001b[32m [repeated 11x across cluster]\u001b[0m\n","399/696 [================>.............] - ETA: 6s - loss: 0.1735 - accuracy: 0.9645\n","397/696 [================>.............] - ETA: 6s - loss: 0.1718 - accuracy: 0.9647\n","184/696 [======>.......................] - ETA: 11s - loss: 0.1758 - accuracy: 0.9640\u001b[32m [repeated 6x across cluster]\u001b[0m\n","187/696 [=======>......................] - ETA: 10s - loss: 0.1790 - accuracy: 0.9639\u001b[32m [repeated 2x across cluster]\u001b[0m\n","418/696 [=================>............] - ETA: 6s - loss: 0.1705 - accuracy: 0.9646\n","208/696 [=======>......................] - ETA: 10s - loss: 0.1775 - accuracy: 0.9639\u001b[32m [repeated 9x across cluster]\u001b[0m\n","208/696 [=======>......................] - ETA: 10s - loss: 0.1775 - accuracy: 0.9639\u001b[32m [repeated 8x across cluster]\u001b[0m\n","420/696 [=================>............] - ETA: 6s - loss: 0.1702 - accuracy: 0.9647\n","421/696 [=================>............] - ETA: 5s - loss: 0.1698 - accuracy: 0.9648\n","226/696 [========>.....................] - ETA: 10s - loss: 0.1771 - accuracy: 0.9640\u001b[32m [repeated 5x across cluster]\u001b[0m\n","441/696 [==================>...........] - ETA: 5s - loss: 0.1687 - accuracy: 0.9646\n","441/696 [==================>...........] - ETA: 5s - loss: 0.1687 - accuracy: 0.9646\n","229/696 [========>.....................] - ETA: 10s - loss: 0.1764 - accuracy: 0.9640\u001b[32m [repeated 8x across cluster]\u001b[0m\n","447/696 [==================>...........] - ETA: 5s - loss: 0.1678 - accuracy: 0.9648\n","232/696 [=========>....................] - ETA: 9s - loss: 0.1762 - accuracy: 0.9640 \u001b[32m [repeated 2x across cluster]\u001b[0m\n","253/696 [=========>....................] - ETA: 9s - loss: 0.1745 - accuracy: 0.9641\u001b[32m [repeated 8x across cluster]\u001b[0m\n","465/696 [===================>..........] - ETA: 5s - loss: 0.1689 - accuracy: 0.9646\n","465/696 [===================>..........] - ETA: 5s - loss: 0.1689 - accuracy: 0.9646\n","247/696 [=========>....................] - ETA: 9s - loss: 0.1755 - accuracy: 0.9638\u001b[32m [repeated 6x across cluster]\u001b[0m\n","469/696 [===================>..........] - ETA: 4s - loss: 0.1692 - accuracy: 0.9645\n","256/696 [==========>...................] - ETA: 9s - loss: 0.1751 - accuracy: 0.9641\u001b[32m [repeated 2x across cluster]\u001b[0m\n","274/696 [==========>...................] - ETA: 9s - loss: 0.1728 - accuracy: 0.9644\u001b[32m [repeated 7x across cluster]\u001b[0m\n","276/696 [==========>...................] - ETA: 9s - loss: 0.1717 - accuracy: 0.9646\u001b[32m [repeated 10x across cluster]\u001b[0m\n","489/696 [====================>.........] - ETA: 4s - loss: 0.1675 - accuracy: 0.9647\n","489/696 [====================>.........] - ETA: 4s - loss: 0.1675 - accuracy: 0.9647\n","491/696 [====================>.........] - ETA: 4s - loss: 0.1669 - accuracy: 0.9648\n","501/696 [====================>.........] - ETA: 4s - loss: 0.1650 - accuracy: 0.9651\n","301/696 [===========>..................] - ETA: 8s - loss: 0.1730 - accuracy: 0.9649\u001b[32m [repeated 8x across cluster]\u001b[0m\n","298/696 [===========>..................] - ETA: 8s - loss: 0.1722 - accuracy: 0.9650\u001b[32m [repeated 8x across cluster]\u001b[0m\n","513/696 [=====================>........] - ETA: 4s - loss: 0.1650 - accuracy: 0.9651\n","513/696 [=====================>........] - ETA: 4s - loss: 0.1650 - accuracy: 0.9651\n","515/696 [=====================>........] - ETA: 3s - loss: 0.1653 - accuracy: 0.9650\n","303/696 [============>.................] - ETA: 8s - loss: 0.1721 - accuracy: 0.9650\u001b[32m [repeated 2x across cluster]\u001b[0m\n","321/696 [============>.................] - ETA: 8s - loss: 0.1703 - accuracy: 0.9650\u001b[32m [repeated 8x across cluster]\u001b[0m\n","322/696 [============>.................] - ETA: 8s - loss: 0.1698 - accuracy: 0.9650\u001b[32m [repeated 7x across cluster]\u001b[0m\n","537/696 [======================>.......] - ETA: 3s - loss: 0.1677 - accuracy: 0.9645\n","535/696 [======================>.......] - ETA: 3s - loss: 0.1674 - accuracy: 0.9646\n","536/696 [======================>.......] - ETA: 3s - loss: 0.1677 - accuracy: 0.9646\n","346/696 [=============>................] - ETA: 7s - loss: 0.1730 - accuracy: 0.9648\u001b[32m [repeated 8x across cluster]\u001b[0m\n","345/696 [=============>................] - ETA: 7s - loss: 0.1735 - accuracy: 0.9647\u001b[32m [repeated 10x across cluster]\u001b[0m\n","558/696 [=======================>......] - ETA: 3s - loss: 0.1674 - accuracy: 0.9647\n","558/696 [=======================>......] - ETA: 3s - loss: 0.1674 - accuracy: 0.9647\n","560/696 [=======================>......] - ETA: 2s - loss: 0.1672 - accuracy: 0.9647\n","370/696 [==============>...............] - ETA: 7s - loss: 0.1700 - accuracy: 0.9648\u001b[32m [repeated 10x across cluster]\u001b[0m\n","369/696 [==============>...............] - ETA: 7s - loss: 0.1703 - accuracy: 0.9648\u001b[32m [repeated 7x across cluster]\u001b[0m\n","582/696 [========================>.....] - ETA: 2s - loss: 0.1659 - accuracy: 0.9646\n","584/696 [========================>.....] - ETA: 2s - loss: 0.1657 - accuracy: 0.9646\n","394/696 [===============>..............] - ETA: 6s - loss: 0.1719 - accuracy: 0.9649\u001b[32m [repeated 8x across cluster]\u001b[0m\n","393/696 [===============>..............] - ETA: 6s - loss: 0.1724 - accuracy: 0.9648\u001b[32m [repeated 12x across cluster]\u001b[0m\n","605/696 [=========================>....] - ETA: 2s - loss: 0.1637 - accuracy: 0.9648\n","607/696 [=========================>....] - ETA: 1s - loss: 0.1633 - accuracy: 0.9648\n","417/696 [================>.............] - ETA: 6s - loss: 0.1708 - accuracy: 0.9646\u001b[32m [repeated 9x across cluster]\u001b[0m\n","417/696 [================>.............] - ETA: 6s - loss: 0.1708 - accuracy: 0.9646\u001b[32m [repeated 8x across cluster]\u001b[0m\n","629/696 [==========================>...] - ETA: 1s - loss: 0.1626 - accuracy: 0.9647\n","628/696 [==========================>...] - ETA: 1s - loss: 0.1628 - accuracy: 0.9647\n","632/696 [==========================>...] - ETA: 1s - loss: 0.1624 - accuracy: 0.9646\n","439/696 [=================>............] - ETA: 5s - loss: 0.1683 - accuracy: 0.9648\u001b[32m [repeated 9x across cluster]\u001b[0m\n","438/696 [=================>............] - ETA: 5s - loss: 0.1686 - accuracy: 0.9647\u001b[32m [repeated 8x across cluster]\u001b[0m\n","652/696 [===========================>..] - ETA: 0s - loss: 0.1616 - accuracy: 0.9650\n","652/696 [===========================>..] - ETA: 0s - loss: 0.1616 - accuracy: 0.9650\n","658/696 [===========================>..] - ETA: 0s - loss: 0.1615 - accuracy: 0.9650\n","655/696 [===========================>..] - ETA: 0s - loss: 0.1612 - accuracy: 0.9650\n","658/696 [===========================>..] - ETA: 0s - loss: 0.1615 - accuracy: 0.9650\n","463/696 [==================>...........] - ETA: 5s - loss: 0.1678 - accuracy: 0.9647\u001b[32m [repeated 9x across cluster]\u001b[0m\n","462/696 [==================>...........] - ETA: 5s - loss: 0.1672 - accuracy: 0.9648\u001b[32m [repeated 9x across cluster]\u001b[0m\n","673/696 [============================>.] - ETA: 0s - loss: 0.1615 - accuracy: 0.9650\n","676/696 [============================>.] - ETA: 0s - loss: 0.1610 - accuracy: 0.9651\n","679/696 [============================>.] - ETA: 0s - loss: 0.1613 - accuracy: 0.9651\n"]},{"output_type":"stream","name":"stderr","text":["DEBUG flwr 2023-06-25 07:15:29,137 | server.py:182 | evaluate_round 3 received 4 results and 0 failures\n","DEBUG:flwr:evaluate_round 3 received 4 results and 0 failures\n","DEBUG flwr 2023-06-25 07:15:29,139 | server.py:218 | fit_round 4: strategy sampled 4 clients (out of 4)\n","DEBUG:flwr:fit_round 4: strategy sampled 4 clients (out of 4)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[2m\u001b[36m(launch_and_evaluate pid=3053)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r487/696 [===================>..........] - ETA: 4s - loss: 0.1680 - accuracy: 0.9646\u001b[32m [repeated 13x across cluster]\u001b[0m\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3041)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r481/696 [===================>..........] - ETA: 4s - loss: 0.1679 - accuracy: 0.9645\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r484/696 [===================>..........] - ETA: 4s - loss: 0.1669 - accuracy: 0.9647\u001b[32m [repeated 7x across cluster]\u001b[0m\n","696/696 [==============================] - 16s 22ms/step - loss: 0.1621 - accuracy: 0.9650\n","696/696 [==============================] - 16s 22ms/step - loss: 0.1621 - accuracy: 0.9650\n"]},{"output_type":"stream","name":"stderr","text":["DEBUG flwr 2023-06-25 07:21:12,106 | server.py:232 | fit_round 4 received 4 results and 0 failures\n","DEBUG:flwr:fit_round 4 received 4 results and 0 failures\n"]},{"output_type":"stream","name":"stdout","text":["696/696 [==============================] - 2s 3ms/step\n"]},{"output_type":"stream","name":"stderr","text":["INFO flwr 2023-06-25 07:21:17,416 | server.py:119 | fit progress: (4, 0.0943123921751976, {'accuracy': 0.9769991015274034, 'precision': 0.9768047521299331, 'recall': 0.9769991015274034, 'f1-score': 0.9766756844094651}, 1442.486572463)\n","INFO:flwr:fit progress: (4, 0.0943123921751976, {'accuracy': 0.9769991015274034, 'precision': 0.9768047521299331, 'recall': 0.9769991015274034, 'f1-score': 0.9766756844094651}, 1442.486572463)\n","DEBUG flwr 2023-06-25 07:21:17,419 | server.py:168 | evaluate_round 4: strategy sampled 4 clients (out of 4)\n","DEBUG:flwr:evaluate_round 4: strategy sampled 4 clients (out of 4)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[2m\u001b[36m(launch_and_evaluate pid=3044)\u001b[0m \r  1/696 [..............................] - ETA: 10:18 - loss: 0.0034 - accuracy: 1.0000\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3041)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r510/696 [====================>.........] - ETA: 4s - loss: 0.1654 - accuracy: 0.9650\u001b[32m [repeated 13x across cluster]\u001b[0m\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3041)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r504/696 [====================>.........] - ETA: 4s - loss: 0.1658 - accuracy: 0.9649\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r507/696 [====================>.........] - ETA: 4s - loss: 0.1654 - accuracy: 0.9651\u001b[32m [repeated 6x across cluster]\u001b[0m\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3053)\u001b[0m \r  1/696 [..............................] - ETA: 10:18 - loss: 0.0034 - accuracy: 1.0000\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3041)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r533/696 [=====================>........] - ETA: 3s - loss: 0.1670 - accuracy: 0.9646\u001b[32m [repeated 13x across cluster]\u001b[0m\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3044)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r530/696 [=====================>........] - ETA: 3s - loss: 0.1678 - accuracy: 0.9645\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r533/696 [=====================>........] - ETA: 3s - loss: 0.1670 - accuracy: 0.9646\u001b[32m [repeated 6x across cluster]\u001b[0m\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3053)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r550/696 [======================>.......] - ETA: 3s - loss: 0.1675 - accuracy: 0.9645\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r553/696 [======================>.......] - ETA: 3s - loss: 0.1676 - accuracy: 0.9646\u001b[32m [repeated 9x across cluster]\u001b[0m\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3044)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r554/696 [======================>.......] - ETA: 3s - loss: 0.1673 - accuracy: 0.9646\u001b[32m [repeated 7x across cluster]\u001b[0m\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3041)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r579/696 [=======================>......] - ETA: 2s - loss: 0.1664 - accuracy: 0.9646\u001b[32m [repeated 8x across cluster]\u001b[0m\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3053)\u001b[0m \r  1/696 [..............................] - ETA: 10:18 - loss: 0.0034 - accuracy: 1.0000\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3053)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r574/696 [=======================>......] - ETA: 2s - loss: 0.1671 - accuracy: 0.9647\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r577/696 [=======================>......] - ETA: 2s - loss: 0.1665 - accuracy: 0.9647\u001b[32m [repeated 9x across cluster]\u001b[0m\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3041)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r603/696 [========================>.....] - ETA: 2s - loss: 0.1635 - accuracy: 0.9648\u001b[32m [repeated 9x across cluster]\u001b[0m\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3044)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r599/696 [========================>.....] - ETA: 2s - loss: 0.1644 - accuracy: 0.9646\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r602/696 [========================>.....] - ETA: 2s - loss: 0.1637 - accuracy: 0.9647\u001b[32m [repeated 10x across cluster]\u001b[0m\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3053)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r622/696 [=========================>....] - ETA: 1s - loss: 0.1630 - accuracy: 0.9648\u001b[32m [repeated 9x across cluster]\u001b[0m\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3041)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r624/696 [=========================>....] - ETA: 1s - loss: 0.1627 - accuracy: 0.9648\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r626/696 [=========================>....] - ETA: 1s - loss: 0.1632 - accuracy: 0.9647\u001b[32m [repeated 9x across cluster]\u001b[0m\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3053)\u001b[0m \r  1/696 [..............................] - ETA: 10:18 - loss: 0.0034 - accuracy: 1.0000\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3053)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r649/696 [==========================>...] - ETA: 1s - loss: 0.1614 - accuracy: 0.9649\u001b[32m [repeated 10x across cluster]\u001b[0m\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3044)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r646/696 [==========================>...] - ETA: 1s - loss: 0.1617 - accuracy: 0.9648\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r649/696 [==========================>...] - ETA: 1s - loss: 0.1614 - accuracy: 0.9649\u001b[32m [repeated 7x across cluster]\u001b[0m\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3041)\u001b[0m \r  1/696 [..............................] - ETA: 10:18 - loss: 0.0034 - accuracy: 1.0000\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3041)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r668/696 [===========================>..] - ETA: 0s - loss: 0.1612 - accuracy: 0.9650\u001b[32m [repeated 6x across cluster]\u001b[0m\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3053)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r667/696 [===========================>..] - ETA: 0s - loss: 0.1615 - accuracy: 0.9650\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r670/696 [===========================>..] - ETA: 0s - loss: 0.1614 - accuracy: 0.9651\u001b[32m [repeated 7x across cluster]\u001b[0m\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3041)\u001b[0m \r  1/696 [..............................] - ETA: 10:18 - loss: 0.0034 - accuracy: 1.0000\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3041)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r692/696 [============================>.] - ETA: 0s - loss: 0.1617 - accuracy: 0.9650\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r695/696 [============================>.] - ETA: 0s - loss: 0.1620 - accuracy: 0.9650\u001b[32m [repeated 11x across cluster]\u001b[0m\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3041)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r683/696 [============================>.] - ETA: 0s - loss: 0.1607 - accuracy: 0.9651\u001b[32m [repeated 3x across cluster]\u001b[0m\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3053)\u001b[0m \r  1/696 [..............................] - ETA: 10:18 - loss: 0.0034 - accuracy: 1.0000\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3041)\u001b[0m \r  1/696 [..............................] - ETA: 10:18 - loss: 0.0034 - accuracy: 1.0000\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3052)\u001b[0m \r  1/696 [..............................] - ETA: 9:49 - loss: 0.0034 - accuracy: 1.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r  4/696 [..............................] - ETA: 13s - loss: 0.0572 - accuracy: 0.9844 \n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3044)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r  4/696 [..............................] - ETA: 15s - loss: 0.0572 - accuracy: 0.9844  \n","  7/696 [..............................] - ETA: 14s - loss: 0.0628 - accuracy: 0.9866\n"," 10/696 [..............................] - ETA: 14s - loss: 0.0664 - accuracy: 0.9844\n"," 16/696 [..............................] - ETA: 14s - loss: 0.0598 - accuracy: 0.9844\n"," 25/696 [>.............................] - ETA: 14s - loss: 0.1153 - accuracy: 0.9750\n"," 28/696 [>.............................] - ETA: 14s - loss: 0.1088 - accuracy: 0.9754\n"," 25/696 [>.............................] - ETA: 14s - loss: 0.1153 - accuracy: 0.9750\n"," 49/696 [=>............................] - ETA: 13s - loss: 0.0976 - accuracy: 0.9764\n"," 52/696 [=>............................] - ETA: 13s - loss: 0.0972 - accuracy: 0.9754\n"," 49/696 [=>............................] - ETA: 13s - loss: 0.0976 - accuracy: 0.9764\n"," 70/696 [==>...........................] - ETA: 13s - loss: 0.1111 - accuracy: 0.9728\n"," 70/696 [==>...........................] - ETA: 13s - loss: 0.1111 - accuracy: 0.9728\n"," 76/696 [==>...........................] - ETA: 13s - loss: 0.1088 - accuracy: 0.9733\n"," 82/696 [==>...........................] - ETA: 13s - loss: 0.1070 - accuracy: 0.9737\n"," 94/696 [===>..........................] - ETA: 12s - loss: 0.1048 - accuracy: 0.9734\n"," 94/696 [===>..........................] - ETA: 13s - loss: 0.1048 - accuracy: 0.9734\n","100/696 [===>..........................] - ETA: 12s - loss: 0.1029 - accuracy: 0.9734\n","118/696 [====>.........................] - ETA: 12s - loss: 0.1011 - accuracy: 0.9746\n","121/696 [====>.........................] - ETA: 12s - loss: 0.1019 - accuracy: 0.9742\n","124/696 [====>.........................] - ETA: 12s - loss: 0.0999 - accuracy: 0.9748\n","142/696 [=====>........................] - ETA: 12s - loss: 0.1034 - accuracy: 0.9745\n","145/696 [=====>........................] - ETA: 11s - loss: 0.1024 - accuracy: 0.9744\n","142/696 [=====>........................] - ETA: 12s - loss: 0.1034 - accuracy: 0.9745\n","163/696 [======>.......................] - ETA: 11s - loss: 0.0983 - accuracy: 0.9758\n","163/696 [======>.......................] - ETA: 11s - loss: 0.0983 - accuracy: 0.9758\n","169/696 [======>.......................] - ETA: 11s - loss: 0.1007 - accuracy: 0.9750\n","187/696 [=======>......................] - ETA: 11s - loss: 0.1032 - accuracy: 0.9738\n","187/696 [=======>......................] - ETA: 11s - loss: 0.1032 - accuracy: 0.9738\n","193/696 [=======>......................] - ETA: 10s - loss: 0.1041 - accuracy: 0.9738\n","211/696 [========>.....................] - ETA: 10s - loss: 0.1017 - accuracy: 0.9744\n","211/696 [========>.....................] - ETA: 10s - loss: 0.1017 - accuracy: 0.9744\n","214/696 [========>.....................] - ETA: 10s - loss: 0.1015 - accuracy: 0.9744\n","213/696 [========>.....................] - ETA: 10s - loss: 0.1020 - accuracy: 0.9743\n","232/696 [=========>....................] - ETA: 10s - loss: 0.1010 - accuracy: 0.9747\n","235/696 [=========>....................] - ETA: 10s - loss: 0.1012 - accuracy: 0.9747\n","235/696 [=========>....................] - ETA: 10s - loss: 0.1012 - accuracy: 0.9747\n","235/696 [=========>....................] - ETA: 10s - loss: 0.1012 - accuracy: 0.9747\n","238/696 [=========>....................] - ETA: 9s - loss: 0.1005 - accuracy: 0.9749 \n","238/696 [=========>....................] - ETA: 9s - loss: 0.1005 - accuracy: 0.9749 \n"," 19/696 [..............................] - ETA: 14s - loss: 0.0703 - accuracy: 0.9803\u001b[32m [repeated 4x across cluster]\u001b[0m\n","241/696 [=========>....................] - ETA: 9s - loss: 0.0996 - accuracy: 0.9751\n","244/696 [=========>....................] - ETA: 9s - loss: 0.0997 - accuracy: 0.9752\n"," 19/696 [..............................] - ETA: 14s - loss: 0.0703 - accuracy: 0.9803\u001b[32m [repeated 7x across cluster]\u001b[0m\n","243/696 [=========>....................] - ETA: 9s - loss: 0.0996 - accuracy: 0.9752\n","250/696 [=========>....................] - ETA: 9s - loss: 0.0993 - accuracy: 0.9750\n","256/696 [==========>...................] - ETA: 9s - loss: 0.0999 - accuracy: 0.9750\n","259/696 [==========>...................] - ETA: 9s - loss: 0.0996 - accuracy: 0.9751\n"," 43/696 [>.............................] - ETA: 14s - loss: 0.0907 - accuracy: 0.9775\u001b[32m [repeated 6x across cluster]\u001b[0m\n"," 46/696 [>.............................] - ETA: 13s - loss: 0.0885 - accuracy: 0.9783\u001b[32m [repeated 10x across cluster]\u001b[0m\n","259/696 [==========>...................] - ETA: 9s - loss: 0.0996 - accuracy: 0.9751\n","262/696 [==========>...................] - ETA: 9s - loss: 0.0990 - accuracy: 0.9753\n","280/696 [===========>..................] - ETA: 9s - loss: 0.0984 - accuracy: 0.9754\n","283/696 [===========>..................] - ETA: 9s - loss: 0.0978 - accuracy: 0.9755\n"," 66/696 [=>............................] - ETA: 13s - loss: 0.1098 - accuracy: 0.9730\u001b[32m [repeated 6x across cluster]\u001b[0m\n"," 63/696 [=>............................] - ETA: 13s - loss: 0.1137 - accuracy: 0.9722\u001b[32m [repeated 8x across cluster]\u001b[0m\n","289/696 [===========>..................] - ETA: 8s - loss: 0.0985 - accuracy: 0.9753\n"," 72/696 [==>...........................] - ETA: 13s - loss: 0.1097 - accuracy: 0.9731\u001b[32m [repeated 2x across cluster]\u001b[0m\n"," 90/696 [==>...........................] - ETA: 13s - loss: 0.1089 - accuracy: 0.9726\u001b[32m [repeated 9x across cluster]\u001b[0m\n","304/696 [============>.................] - ETA: 8s - loss: 0.1000 - accuracy: 0.9747\n","303/696 [============>.................] - ETA: 8s - loss: 0.1003 - accuracy: 0.9746\n"," 87/696 [==>...........................] - ETA: 13s - loss: 0.1116 - accuracy: 0.9723\u001b[32m [repeated 6x across cluster]\u001b[0m\n","310/696 [============>.................] - ETA: 8s - loss: 0.0988 - accuracy: 0.9749\n","325/696 [=============>................] - ETA: 8s - loss: 0.0987 - accuracy: 0.9750\n","328/696 [=============>................] - ETA: 8s - loss: 0.1000 - accuracy: 0.9748\n","328/696 [=============>................] - ETA: 8s - loss: 0.1000 - accuracy: 0.9748\n","112/696 [===>..........................] - ETA: 12s - loss: 0.1051 - accuracy: 0.9735\u001b[32m [repeated 10x across cluster]\u001b[0m\n","328/696 [=============>................] - ETA: 8s - loss: 0.1000 - accuracy: 0.9748\n","111/696 [===>..........................] - ETA: 12s - loss: 0.1057 - accuracy: 0.9735\u001b[32m [repeated 7x across cluster]\u001b[0m\n","349/696 [==============>...............] - ETA: 7s - loss: 0.0991 - accuracy: 0.9749\n","352/696 [==============>...............] - ETA: 7s - loss: 0.0984 - accuracy: 0.9751\n","117/696 [====>.........................] - ETA: 12s - loss: 0.1019 - accuracy: 0.9744\u001b[32m [repeated 2x across cluster]\u001b[0m\n","135/696 [====>.........................] - ETA: 12s - loss: 0.1051 - accuracy: 0.9741\u001b[32m [repeated 9x across cluster]\u001b[0m\n","352/696 [==============>...............] - ETA: 7s - loss: 0.0984 - accuracy: 0.9751\n","136/696 [====>.........................] - ETA: 12s - loss: 0.1065 - accuracy: 0.9738\u001b[32m [repeated 6x across cluster]\u001b[0m\n","373/696 [===============>..............] - ETA: 7s - loss: 0.0981 - accuracy: 0.9751\n","376/696 [===============>..............] - ETA: 6s - loss: 0.0978 - accuracy: 0.9751\n","160/696 [=====>........................] - ETA: 11s - loss: 0.0958 - accuracy: 0.9764\u001b[32m [repeated 6x across cluster]\u001b[0m\n","159/696 [=====>........................] - ETA: 11s - loss: 0.0955 - accuracy: 0.9764\u001b[32m [repeated 8x across cluster]\u001b[0m\n","376/696 [===============>..............] - ETA: 6s - loss: 0.0978 - accuracy: 0.9751\n","376/696 [===============>..............] - ETA: 6s - loss: 0.0978 - accuracy: 0.9751\n","394/696 [===============>..............] - ETA: 6s - loss: 0.0983 - accuracy: 0.9752\n","183/696 [======>.......................] - ETA: 11s - loss: 0.1010 - accuracy: 0.9746\u001b[32m [repeated 8x across cluster]\u001b[0m\n","397/696 [================>.............] - ETA: 6s - loss: 0.0980 - accuracy: 0.9753\n","400/696 [================>.............] - ETA: 6s - loss: 0.0992 - accuracy: 0.9751\n","180/696 [======>.......................] - ETA: 11s - loss: 0.1019 - accuracy: 0.9745\u001b[32m [repeated 8x across cluster]\u001b[0m\n","399/696 [================>.............] - ETA: 6s - loss: 0.0994 - accuracy: 0.9750\n","418/696 [=================>............] - ETA: 6s - loss: 0.0978 - accuracy: 0.9753\n","418/696 [=================>............] - ETA: 6s - loss: 0.0978 - accuracy: 0.9753\n","207/696 [=======>......................] - ETA: 10s - loss: 0.1013 - accuracy: 0.9743\u001b[32m [repeated 11x across cluster]\u001b[0m\n","421/696 [=================>............] - ETA: 5s - loss: 0.0972 - accuracy: 0.9755\n","420/696 [=================>............] - ETA: 6s - loss: 0.0974 - accuracy: 0.9754\n","421/696 [=================>............] - ETA: 5s - loss: 0.0972 - accuracy: 0.9755\n","424/696 [=================>............] - ETA: 5s - loss: 0.0973 - accuracy: 0.9755\n","204/696 [=======>......................] - ETA: 10s - loss: 0.1023 - accuracy: 0.9741\u001b[32m [repeated 7x across cluster]\u001b[0m\n","427/696 [=================>............] - ETA: 5s - loss: 0.0980 - accuracy: 0.9754\n","442/696 [==================>...........] - ETA: 5s - loss: 0.0967 - accuracy: 0.9758\n","445/696 [==================>...........] - ETA: 5s - loss: 0.0966 - accuracy: 0.9758\n","445/696 [==================>...........] - ETA: 5s - loss: 0.0966 - accuracy: 0.9758\n","231/696 [========>.....................] - ETA: 10s - loss: 0.0996 - accuracy: 0.9751\u001b[32m [repeated 8x across cluster]\u001b[0m\n","445/696 [==================>...........] - ETA: 5s - loss: 0.0966 - accuracy: 0.9758\n","441/696 [==================>...........] - ETA: 5s - loss: 0.0969 - accuracy: 0.9758\n","228/696 [========>.....................] - ETA: 10s - loss: 0.1002 - accuracy: 0.9749\u001b[32m [repeated 7x across cluster]\u001b[0m\n","466/696 [===================>..........] - ETA: 5s - loss: 0.0970 - accuracy: 0.9759\n","237/696 [=========>....................] - ETA: 10s - loss: 0.1009 - accuracy: 0.9748\u001b[32m [repeated 3x across cluster]\u001b[0m\n","469/696 [===================>..........] - ETA: 4s - loss: 0.0974 - accuracy: 0.9759\n","465/696 [===================>..........] - ETA: 5s - loss: 0.0972 - accuracy: 0.9759\n","472/696 [===================>..........] - ETA: 4s - loss: 0.0970 - accuracy: 0.9760\n","255/696 [=========>....................] - ETA: 9s - loss: 0.0996 - accuracy: 0.9751\u001b[32m [repeated 4x across cluster]\u001b[0m\n","252/696 [=========>....................] - ETA: 9s - loss: 0.0993 - accuracy: 0.9750\u001b[32m [repeated 5x across cluster]\u001b[0m\n","491/696 [====================>.........] - ETA: 4s - loss: 0.0968 - accuracy: 0.9763\n","276/696 [==========>...................] - ETA: 9s - loss: 0.0986 - accuracy: 0.9754\u001b[32m [repeated 10x across cluster]\u001b[0m\n","489/696 [====================>.........] - ETA: 4s - loss: 0.0972 - accuracy: 0.9762\n","489/696 [====================>.........] - ETA: 4s - loss: 0.0972 - accuracy: 0.9762\n","277/696 [==========>...................] - ETA: 9s - loss: 0.0987 - accuracy: 0.9754\u001b[32m [repeated 7x across cluster]\u001b[0m\n","300/696 [===========>..................] - ETA: 8s - loss: 0.0998 - accuracy: 0.9747\u001b[32m [repeated 7x across cluster]\u001b[0m\n","511/696 [=====================>........] - ETA: 4s - loss: 0.0969 - accuracy: 0.9764\n","514/696 [=====================>........] - ETA: 3s - loss: 0.0967 - accuracy: 0.9764\n","297/696 [===========>..................] - ETA: 8s - loss: 0.1000 - accuracy: 0.9749\u001b[32m [repeated 10x across cluster]\u001b[0m\n","324/696 [============>.................] - ETA: 8s - loss: 0.0983 - accuracy: 0.9750\u001b[32m [repeated 8x across cluster]\u001b[0m\n","534/696 [======================>.......] - ETA: 3s - loss: 0.0963 - accuracy: 0.9764\n","538/696 [======================>.......] - ETA: 3s - loss: 0.0959 - accuracy: 0.9765\n","321/696 [============>.................] - ETA: 8s - loss: 0.0984 - accuracy: 0.9750\u001b[32m [repeated 8x across cluster]\u001b[0m\n","550/696 [======================>.......] - ETA: 3s - loss: 0.0961 - accuracy: 0.9764\n","345/696 [=============>................] - ETA: 7s - loss: 0.0997 - accuracy: 0.9747\u001b[32m [repeated 9x across cluster]\u001b[0m\n","345/696 [=============>................] - ETA: 7s - loss: 0.0997 - accuracy: 0.9747\u001b[32m [repeated 6x across cluster]\u001b[0m\n","558/696 [=======================>......] - ETA: 3s - loss: 0.0962 - accuracy: 0.9765\n","562/696 [=======================>......] - ETA: 2s - loss: 0.0959 - accuracy: 0.9766\n","580/696 [========================>.....] - ETA: 2s - loss: 0.0955 - accuracy: 0.9766\n","369/696 [==============>...............] - ETA: 7s - loss: 0.0977 - accuracy: 0.9754\u001b[32m [repeated 9x across cluster]\u001b[0m\n","369/696 [==============>...............] - ETA: 7s - loss: 0.0977 - accuracy: 0.9754\u001b[32m [repeated 9x across cluster]\u001b[0m\n","583/696 [========================>.....] - ETA: 2s - loss: 0.0954 - accuracy: 0.9766\n","588/696 [========================>.....] - ETA: 2s - loss: 0.0950 - accuracy: 0.9767\n","604/696 [=========================>....] - ETA: 2s - loss: 0.0941 - accuracy: 0.9767\n","393/696 [===============>..............] - ETA: 6s - loss: 0.0983 - accuracy: 0.9752\u001b[32m [repeated 10x across cluster]\u001b[0m\n","394/696 [===============>..............] - ETA: 6s - loss: 0.0983 - accuracy: 0.9752\u001b[32m [repeated 6x across cluster]\u001b[0m\n","607/696 [=========================>....] - ETA: 1s - loss: 0.0942 - accuracy: 0.9767\n","611/696 [=========================>....] - ETA: 1s - loss: 0.0942 - accuracy: 0.9767\n","622/696 [=========================>....] - ETA: 1s - loss: 0.0947 - accuracy: 0.9767\n","628/696 [==========================>...] - ETA: 1s - loss: 0.0948 - accuracy: 0.9767\n","417/696 [================>.............] - ETA: 6s - loss: 0.0981 - accuracy: 0.9753\u001b[32m [repeated 8x across cluster]\u001b[0m\n","411/696 [================>.............] - ETA: 6s - loss: 0.0993 - accuracy: 0.9750\u001b[32m [repeated 8x across cluster]\u001b[0m\n","629/696 [==========================>...] - ETA: 1s - loss: 0.0947 - accuracy: 0.9767\n","635/696 [==========================>...] - ETA: 1s - loss: 0.0944 - accuracy: 0.9768\n","435/696 [=================>............] - ETA: 5s - loss: 0.0973 - accuracy: 0.9756\u001b[32m [repeated 9x across cluster]\u001b[0m\n","439/696 [=================>............] - ETA: 5s - loss: 0.0968 - accuracy: 0.9757\u001b[32m [repeated 6x across cluster]\u001b[0m\n","650/696 [===========================>..] - ETA: 1s - loss: 0.0937 - accuracy: 0.9770\n","652/696 [===========================>..] - ETA: 0s - loss: 0.0935 - accuracy: 0.9770\n","653/696 [===========================>..] - ETA: 0s - loss: 0.0935 - accuracy: 0.9770\n","659/696 [===========================>..] - ETA: 0s - loss: 0.0934 - accuracy: 0.9771\n","459/696 [==================>...........] - ETA: 5s - loss: 0.0968 - accuracy: 0.9758\u001b[32m [repeated 8x across cluster]\u001b[0m\n","463/696 [==================>...........] - ETA: 5s - loss: 0.0969 - accuracy: 0.9759\u001b[32m [repeated 9x across cluster]\u001b[0m\n","673/696 [============================>.] - ETA: 0s - loss: 0.0943 - accuracy: 0.9770\n","677/696 [============================>.] - ETA: 0s - loss: 0.0942 - accuracy: 0.9771\n","674/696 [============================>.] - ETA: 0s - loss: 0.0942 - accuracy: 0.9770\n"]},{"output_type":"stream","name":"stderr","text":["DEBUG flwr 2023-06-25 07:21:35,160 | server.py:182 | evaluate_round 4 received 4 results and 0 failures\n","DEBUG:flwr:evaluate_round 4 received 4 results and 0 failures\n","DEBUG flwr 2023-06-25 07:21:35,162 | server.py:218 | fit_round 5: strategy sampled 4 clients (out of 4)\n","DEBUG:flwr:fit_round 5: strategy sampled 4 clients (out of 4)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[2m\u001b[36m(launch_and_evaluate pid=3053)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r483/696 [===================>..........] - ETA: 4s - loss: 0.0973 - accuracy: 0.9761\u001b[32m [repeated 7x across cluster]\u001b[0m\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3041)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r483/696 [===================>..........] - ETA: 4s - loss: 0.0973 - accuracy: 0.9761\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r486/696 [===================>..........] - ETA: 4s - loss: 0.0975 - accuracy: 0.9761\u001b[32m [repeated 10x across cluster]\u001b[0m\n","696/696 [==============================] - 16s 22ms/step - loss: 0.0943 - accuracy: 0.9770\n","696/696 [==============================] - 16s 22ms/step - loss: 0.0943 - accuracy: 0.9770\n"]},{"output_type":"stream","name":"stderr","text":["DEBUG flwr 2023-06-25 07:27:18,719 | server.py:232 | fit_round 5 received 4 results and 0 failures\n","DEBUG:flwr:fit_round 5 received 4 results and 0 failures\n"]},{"output_type":"stream","name":"stdout","text":["696/696 [==============================] - 2s 3ms/step\n"]},{"output_type":"stream","name":"stderr","text":["INFO flwr 2023-06-25 07:27:24,087 | server.py:119 | fit progress: (5, 0.049816686660051346, {'accuracy': 0.9847259658580413, 'precision': 0.9848300640330876, 'recall': 0.9847259658580413, 'f1-score': 0.9841044000402451}, 1809.1574508049998)\n","INFO:flwr:fit progress: (5, 0.049816686660051346, {'accuracy': 0.9847259658580413, 'precision': 0.9848300640330876, 'recall': 0.9847259658580413, 'f1-score': 0.9841044000402451}, 1809.1574508049998)\n","DEBUG flwr 2023-06-25 07:27:24,090 | server.py:168 | evaluate_round 5: strategy sampled 4 clients (out of 4)\n","DEBUG:flwr:evaluate_round 5: strategy sampled 4 clients (out of 4)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[2m\u001b[36m(launch_and_evaluate pid=3044)\u001b[0m \r  1/696 [..............................] - ETA: 10:22 - loss: 0.0037 - accuracy: 1.0000\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3053)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r504/696 [====================>.........] - ETA: 4s - loss: 0.0967 - accuracy: 0.9763\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r507/696 [====================>.........] - ETA: 4s - loss: 0.0968 - accuracy: 0.9763\u001b[32m [repeated 9x across cluster]\u001b[0m\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3053)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r510/696 [====================>.........] - ETA: 4s - loss: 0.0968 - accuracy: 0.9764\u001b[32m [repeated 9x across cluster]\u001b[0m\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3041)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r531/696 [=====================>........] - ETA: 3s - loss: 0.0966 - accuracy: 0.9763\u001b[32m [repeated 9x across cluster]\u001b[0m\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3053)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r528/696 [=====================>........] - ETA: 3s - loss: 0.0964 - accuracy: 0.9765\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r531/696 [=====================>........] - ETA: 3s - loss: 0.0966 - accuracy: 0.9763\u001b[32m [repeated 9x across cluster]\u001b[0m\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3041)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r555/696 [======================>.......] - ETA: 3s - loss: 0.0960 - accuracy: 0.9765\u001b[32m [repeated 9x across cluster]\u001b[0m\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3053)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r552/696 [======================>.......] - ETA: 3s - loss: 0.0963 - accuracy: 0.9764\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r555/696 [======================>.......] - ETA: 3s - loss: 0.0960 - accuracy: 0.9765\u001b[32m [repeated 10x across cluster]\u001b[0m\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3041)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r578/696 [=======================>......] - ETA: 2s - loss: 0.0955 - accuracy: 0.9766\u001b[32m [repeated 8x across cluster]\u001b[0m\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3053)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r576/696 [=======================>......] - ETA: 2s - loss: 0.0953 - accuracy: 0.9767\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r579/696 [=======================>......] - ETA: 2s - loss: 0.0956 - accuracy: 0.9766\u001b[32m [repeated 9x across cluster]\u001b[0m\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3052)\u001b[0m \r  1/696 [..............................] - ETA: 10:22 - loss: 0.0037 - accuracy: 1.0000\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3053)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r603/696 [========================>.....] - ETA: 2s - loss: 0.0940 - accuracy: 0.9767\u001b[32m [repeated 11x across cluster]\u001b[0m\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3053)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r594/696 [========================>.....] - ETA: 2s - loss: 0.0948 - accuracy: 0.9766\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r597/696 [========================>.....] - ETA: 2s - loss: 0.0947 - accuracy: 0.9766\u001b[32m [repeated 7x across cluster]\u001b[0m\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3052)\u001b[0m \r  1/696 [..............................] - ETA: 10:22 - loss: 0.0037 - accuracy: 1.0000\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3041)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r626/696 [=========================>....] - ETA: 1s - loss: 0.0950 - accuracy: 0.9767\u001b[32m [repeated 8x across cluster]\u001b[0m\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3053)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r623/696 [=========================>....] - ETA: 1s - loss: 0.0946 - accuracy: 0.9768\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r626/696 [=========================>....] - ETA: 1s - loss: 0.0950 - accuracy: 0.9767\u001b[32m [repeated 9x across cluster]\u001b[0m\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3053)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r647/696 [==========================>...] - ETA: 1s - loss: 0.0938 - accuracy: 0.9770\u001b[32m [repeated 9x across cluster]\u001b[0m\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3053)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r641/696 [==========================>...] - ETA: 1s - loss: 0.0940 - accuracy: 0.9768\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r644/696 [==========================>...] - ETA: 1s - loss: 0.0939 - accuracy: 0.9769\u001b[32m [repeated 7x across cluster]\u001b[0m\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3053)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r671/696 [===========================>..] - ETA: 0s - loss: 0.0942 - accuracy: 0.9770\u001b[32m [repeated 8x across cluster]\u001b[0m\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3041)\u001b[0m \r  1/696 [..............................] - ETA: 10:22 - loss: 0.0037 - accuracy: 1.0000\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3053)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r665/696 [===========================>..] - ETA: 0s - loss: 0.0942 - accuracy: 0.9770\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r668/696 [===========================>..] - ETA: 0s - loss: 0.0938 - accuracy: 0.9771\u001b[32m [repeated 8x across cluster]\u001b[0m\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3041)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r692/696 [============================>.] - ETA: 0s - loss: 0.0939 - accuracy: 0.9771\u001b[32m [repeated 7x across cluster]\u001b[0m\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3053)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r689/696 [============================>.] - ETA: 0s - loss: 0.0937 - accuracy: 0.9772\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r692/696 [============================>.] - ETA: 0s - loss: 0.0939 - accuracy: 0.9771\u001b[32m [repeated 9x across cluster]\u001b[0m\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3053)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r695/696 [============================>.] - ETA: 0s - loss: 0.0941 - accuracy: 0.9771\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r696/696 [==============================] - 16s 22ms/step - loss: 0.0943 - accuracy: 0.9770\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3041)\u001b[0m \r  1/696 [..............................] - ETA: 9:55 - loss: 0.0037 - accuracy: 1.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r  4/696 [..............................] - ETA: 14s - loss: 0.0646 - accuracy: 0.9844 \n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3044)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r  4/696 [..............................] - ETA: 14s - loss: 0.0646 - accuracy: 0.9844  \n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3044)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r  7/696 [..............................] - ETA: 14s - loss: 0.0374 - accuracy: 0.9911\n","  7/696 [..............................] - ETA: 14s - loss: 0.0374 - accuracy: 0.9911\n"," 13/696 [..............................] - ETA: 14s - loss: 0.0218 - accuracy: 0.9952\n"," 25/696 [>.............................] - ETA: 15s - loss: 0.0675 - accuracy: 0.9887\n"," 28/696 [>.............................] - ETA: 14s - loss: 0.0626 - accuracy: 0.9888\n"," 25/696 [>.............................] - ETA: 15s - loss: 0.0675 - accuracy: 0.9887\n"," 49/696 [=>............................] - ETA: 14s - loss: 0.0581 - accuracy: 0.9860\n"," 49/696 [=>............................] - ETA: 14s - loss: 0.0581 - accuracy: 0.9860\n"," 55/696 [=>............................] - ETA: 14s - loss: 0.0602 - accuracy: 0.9841\n"," 72/696 [==>...........................] - ETA: 14s - loss: 0.0596 - accuracy: 0.9835\n"," 73/696 [==>...........................] - ETA: 14s - loss: 0.0597 - accuracy: 0.9833\n"," 96/696 [===>..........................] - ETA: 13s - loss: 0.0532 - accuracy: 0.9854\n"," 94/696 [===>..........................] - ETA: 13s - loss: 0.0539 - accuracy: 0.9854\n","119/696 [====>.........................] - ETA: 13s - loss: 0.0556 - accuracy: 0.9845\n","118/696 [====>.........................] - ETA: 13s - loss: 0.0552 - accuracy: 0.9846\n","125/696 [====>.........................] - ETA: 13s - loss: 0.0548 - accuracy: 0.9847\n","117/696 [====>.........................] - ETA: 13s - loss: 0.0556 - accuracy: 0.9845\n","142/696 [=====>........................] - ETA: 12s - loss: 0.0554 - accuracy: 0.9850\n","142/696 [=====>........................] - ETA: 12s - loss: 0.0554 - accuracy: 0.9850\n","148/696 [=====>........................] - ETA: 12s - loss: 0.0551 - accuracy: 0.9848\n","163/696 [======>.......................] - ETA: 12s - loss: 0.0532 - accuracy: 0.9852\n","163/696 [======>.......................] - ETA: 12s - loss: 0.0532 - accuracy: 0.9852\n","166/696 [======>.......................] - ETA: 12s - loss: 0.0536 - accuracy: 0.9848\n","172/696 [======>.......................] - ETA: 11s - loss: 0.0530 - accuracy: 0.9849\n","187/696 [=======>......................] - ETA: 11s - loss: 0.0547 - accuracy: 0.9845\n","190/696 [=======>......................] - ETA: 11s - loss: 0.0543 - accuracy: 0.9845\n","193/696 [=======>......................] - ETA: 11s - loss: 0.0543 - accuracy: 0.9846\n","211/696 [========>.....................] - ETA: 10s - loss: 0.0530 - accuracy: 0.9846\n","209/696 [========>.....................] - ETA: 10s - loss: 0.0535 - accuracy: 0.9844\n","217/696 [========>.....................] - ETA: 10s - loss: 0.0533 - accuracy: 0.9846\n","  1/696 [..............................] - ETA: 10:57 - loss: 0.0037 - accuracy: 1.0000\u001b[32m [repeated 2x across cluster]\u001b[0m\n","219/696 [========>.....................] - ETA: 10s - loss: 0.0528 - accuracy: 0.9847\n"," 19/696 [..............................] - ETA: 15s - loss: 0.0300 - accuracy: 0.9918\u001b[32m [repeated 7x across cluster]\u001b[0m\n","232/696 [=========>....................] - ETA: 10s - loss: 0.0517 - accuracy: 0.9850\n","235/696 [=========>....................] - ETA: 10s - loss: 0.0520 - accuracy: 0.9848\n"," 22/696 [..............................] - ETA: 15s - loss: 0.0271 - accuracy: 0.9929\u001b[32m [repeated 6x across cluster]\u001b[0m\n","235/696 [=========>....................] - ETA: 10s - loss: 0.0520 - accuracy: 0.9848\n","241/696 [=========>....................] - ETA: 10s - loss: 0.0517 - accuracy: 0.9847\n","234/696 [=========>....................] - ETA: 10s - loss: 0.0515 - accuracy: 0.9850\n"," 43/696 [>.............................] - ETA: 14s - loss: 0.0515 - accuracy: 0.9876\u001b[32m [repeated 12x across cluster]\u001b[0m\n"," 46/696 [>.............................] - ETA: 14s - loss: 0.0520 - accuracy: 0.9878\u001b[32m [repeated 7x across cluster]\u001b[0m\n","256/696 [==========>...................] - ETA: 9s - loss: 0.0502 - accuracy: 0.9847\n","254/696 [=========>....................] - ETA: 9s - loss: 0.0504 - accuracy: 0.9847\n","259/696 [==========>...................] - ETA: 9s - loss: 0.0500 - accuracy: 0.9848\n","265/696 [==========>...................] - ETA: 9s - loss: 0.0495 - accuracy: 0.9848\n"," 67/696 [=>............................] - ETA: 14s - loss: 0.0613 - accuracy: 0.9837\u001b[32m [repeated 8x across cluster]\u001b[0m\n","267/696 [==========>...................] - ETA: 9s - loss: 0.0492 - accuracy: 0.9849\n","280/696 [===========>..................] - ETA: 9s - loss: 0.0499 - accuracy: 0.9847\n"," 67/696 [=>............................] - ETA: 14s - loss: 0.0613 - accuracy: 0.9837\u001b[32m [repeated 8x across cluster]\u001b[0m\n","283/696 [===========>..................] - ETA: 9s - loss: 0.0494 - accuracy: 0.9849\n","286/696 [===========>..................] - ETA: 9s - loss: 0.0489 - accuracy: 0.9850\n"," 84/696 [==>...........................] - ETA: 14s - loss: 0.0528 - accuracy: 0.9855\u001b[32m [repeated 8x across cluster]\u001b[0m\n","304/696 [============>.................] - ETA: 8s - loss: 0.0490 - accuracy: 0.9848\n"," 90/696 [==>...........................] - ETA: 13s - loss: 0.0562 - accuracy: 0.9847\u001b[32m [repeated 10x across cluster]\u001b[0m\n","304/696 [============>.................] - ETA: 8s - loss: 0.0490 - accuracy: 0.9848\n","310/696 [============>.................] - ETA: 8s - loss: 0.0498 - accuracy: 0.9846\n","113/696 [===>..........................] - ETA: 13s - loss: 0.0570 - accuracy: 0.9842\u001b[32m [repeated 10x across cluster]\u001b[0m\n","325/696 [=============>................] - ETA: 8s - loss: 0.0487 - accuracy: 0.9849\n","111/696 [===>..........................] - ETA: 13s - loss: 0.0573 - accuracy: 0.9842\u001b[32m [repeated 8x across cluster]\u001b[0m\n","328/696 [=============>................] - ETA: 8s - loss: 0.0487 - accuracy: 0.9849\n","328/696 [=============>................] - ETA: 8s - loss: 0.0487 - accuracy: 0.9849\n","334/696 [=============>................] - ETA: 8s - loss: 0.0488 - accuracy: 0.9848\n","349/696 [==============>...............] - ETA: 7s - loss: 0.0494 - accuracy: 0.9848\n","352/696 [==============>...............] - ETA: 7s - loss: 0.0493 - accuracy: 0.9848\n","137/696 [====>.........................] - ETA: 12s - loss: 0.0571 - accuracy: 0.9845\u001b[32m [repeated 7x across cluster]\u001b[0m\n","135/696 [====>.........................] - ETA: 12s - loss: 0.0568 - accuracy: 0.9845\u001b[32m [repeated 11x across cluster]\u001b[0m\n","352/696 [==============>...............] - ETA: 7s - loss: 0.0493 - accuracy: 0.9848\n","358/696 [==============>...............] - ETA: 7s - loss: 0.0495 - accuracy: 0.9848\n","373/696 [===============>..............] - ETA: 7s - loss: 0.0511 - accuracy: 0.9845\n","376/696 [===============>..............] - ETA: 7s - loss: 0.0512 - accuracy: 0.9844\n","376/696 [===============>..............] - ETA: 7s - loss: 0.0512 - accuracy: 0.9844\n","159/696 [=====>........................] - ETA: 12s - loss: 0.0522 - accuracy: 0.9855\u001b[32m [repeated 9x across cluster]\u001b[0m\n","377/696 [===============>..............] - ETA: 7s - loss: 0.0511 - accuracy: 0.9843\n","161/696 [=====>........................] - ETA: 12s - loss: 0.0516 - accuracy: 0.9856\u001b[32m [repeated 7x across cluster]\u001b[0m\n","397/696 [================>.............] - ETA: 6s - loss: 0.0518 - accuracy: 0.9843\n","397/696 [================>.............] - ETA: 6s - loss: 0.0518 - accuracy: 0.9843\n","183/696 [======>.......................] - ETA: 11s - loss: 0.0539 - accuracy: 0.9848\u001b[32m [repeated 7x across cluster]\u001b[0m\n","395/696 [================>.............] - ETA: 6s - loss: 0.0513 - accuracy: 0.9845\n","403/696 [================>.............] - ETA: 6s - loss: 0.0520 - accuracy: 0.9842\n","185/696 [======>.......................] - ETA: 11s - loss: 0.0544 - accuracy: 0.9846\u001b[32m [repeated 8x across cluster]\u001b[0m\n","418/696 [=================>............] - ETA: 6s - loss: 0.0508 - accuracy: 0.9845\n","418/696 [=================>............] - ETA: 6s - loss: 0.0508 - accuracy: 0.9845\n","421/696 [=================>............] - ETA: 6s - loss: 0.0507 - accuracy: 0.9846\n","421/696 [=================>............] - ETA: 6s - loss: 0.0507 - accuracy: 0.9846\n","422/696 [=================>............] - ETA: 6s - loss: 0.0510 - accuracy: 0.9844\n","205/696 [=======>......................] - ETA: 11s - loss: 0.0533 - accuracy: 0.9848\u001b[32m [repeated 9x across cluster]\u001b[0m\n","204/696 [=======>......................] - ETA: 11s - loss: 0.0536 - accuracy: 0.9847\u001b[32m [repeated 7x across cluster]\u001b[0m\n","442/696 [==================>...........] - ETA: 5s - loss: 0.0506 - accuracy: 0.9843\n","445/696 [==================>...........] - ETA: 5s - loss: 0.0506 - accuracy: 0.9843\n","210/696 [========>.....................] - ETA: 10s - loss: 0.0533 - accuracy: 0.9845\u001b[32m [repeated 2x across cluster]\u001b[0m\n","228/696 [========>.....................] - ETA: 10s - loss: 0.0522 - accuracy: 0.9851\u001b[32m [repeated 9x across cluster]\u001b[0m\n","446/696 [==================>...........] - ETA: 5s - loss: 0.0505 - accuracy: 0.9843\n","230/696 [========>.....................] - ETA: 10s - loss: 0.0521 - accuracy: 0.9849\u001b[32m [repeated 7x across cluster]\u001b[0m\n","465/696 [===================>..........] - ETA: 5s - loss: 0.0500 - accuracy: 0.9843\n","252/696 [=========>....................] - ETA: 9s - loss: 0.0508 - accuracy: 0.9846 \u001b[32m [repeated 6x across cluster]\u001b[0m\n","468/696 [===================>..........] - ETA: 5s - loss: 0.0498 - accuracy: 0.9844\n","249/696 [=========>....................] - ETA: 10s - loss: 0.0511 - accuracy: 0.9846\u001b[32m [repeated 7x across cluster]\u001b[0m\n","470/696 [===================>..........] - ETA: 4s - loss: 0.0498 - accuracy: 0.9844\n","489/696 [====================>.........] - ETA: 4s - loss: 0.0494 - accuracy: 0.9846\n","258/696 [==========>...................] - ETA: 9s - loss: 0.0502 - accuracy: 0.9847\u001b[32m [repeated 2x across cluster]\u001b[0m\n","488/696 [====================>.........] - ETA: 4s - loss: 0.0495 - accuracy: 0.9846\n","495/696 [====================>.........] - ETA: 4s - loss: 0.0488 - accuracy: 0.9848\n","272/696 [==========>...................] - ETA: 9s - loss: 0.0504 - accuracy: 0.9848\u001b[32m [repeated 8x across cluster]\u001b[0m\n","278/696 [==========>...................] - ETA: 9s - loss: 0.0501 - accuracy: 0.9847\u001b[32m [repeated 7x across cluster]\u001b[0m\n","511/696 [=====================>........] - ETA: 4s - loss: 0.0484 - accuracy: 0.9848\n","513/696 [=====================>........] - ETA: 4s - loss: 0.0482 - accuracy: 0.9849\n","279/696 [===========>..................] - ETA: 9s - loss: 0.0501 - accuracy: 0.9847\u001b[32m [repeated 2x across cluster]\u001b[0m\n","519/696 [=====================>........] - ETA: 3s - loss: 0.0485 - accuracy: 0.9848\n","291/696 [===========>..................] - ETA: 9s - loss: 0.0498 - accuracy: 0.9846\u001b[32m [repeated 5x across cluster]\u001b[0m\n","297/696 [===========>..................] - ETA: 8s - loss: 0.0496 - accuracy: 0.9847\u001b[32m [repeated 9x across cluster]\u001b[0m\n","534/696 [======================>.......] - ETA: 3s - loss: 0.0482 - accuracy: 0.9848\n","537/696 [======================>.......] - ETA: 3s - loss: 0.0481 - accuracy: 0.9848\n","537/696 [======================>.......] - ETA: 3s - loss: 0.0481 - accuracy: 0.9848\n","321/696 [============>.................] - ETA: 8s - loss: 0.0490 - accuracy: 0.9849\u001b[32m [repeated 11x across cluster]\u001b[0m\n","539/696 [======================>.......] - ETA: 3s - loss: 0.0481 - accuracy: 0.9848\n","323/696 [============>.................] - ETA: 8s - loss: 0.0487 - accuracy: 0.9850\u001b[32m [repeated 6x across cluster]\u001b[0m\n","558/696 [=======================>......] - ETA: 3s - loss: 0.0480 - accuracy: 0.9849\n","558/696 [=======================>......] - ETA: 3s - loss: 0.0480 - accuracy: 0.9849\n","557/696 [=======================>......] - ETA: 3s - loss: 0.0480 - accuracy: 0.9849\n","564/696 [=======================>......] - ETA: 2s - loss: 0.0481 - accuracy: 0.9849\n","347/696 [=============>................] - ETA: 7s - loss: 0.0490 - accuracy: 0.9848\u001b[32m [repeated 8x across cluster]\u001b[0m\n","345/696 [=============>................] - ETA: 7s - loss: 0.0492 - accuracy: 0.9847\u001b[32m [repeated 7x across cluster]\u001b[0m\n","580/696 [========================>.....] - ETA: 2s - loss: 0.0483 - accuracy: 0.9848\n","582/696 [========================>.....] - ETA: 2s - loss: 0.0482 - accuracy: 0.9848\n","588/696 [========================>.....] - ETA: 2s - loss: 0.0479 - accuracy: 0.9849\n","366/696 [==============>...............] - ETA: 7s - loss: 0.0505 - accuracy: 0.9845\u001b[32m [repeated 8x across cluster]\u001b[0m\n","371/696 [==============>...............] - ETA: 7s - loss: 0.0509 - accuracy: 0.9846\u001b[32m [repeated 7x across cluster]\u001b[0m\n","604/696 [=========================>....] - ETA: 2s - loss: 0.0475 - accuracy: 0.9850\n","606/696 [=========================>....] - ETA: 1s - loss: 0.0475 - accuracy: 0.9850\n","372/696 [===============>..............] - ETA: 7s - loss: 0.0507 - accuracy: 0.9846\u001b[32m [repeated 2x across cluster]\u001b[0m\n","612/696 [=========================>....] - ETA: 1s - loss: 0.0474 - accuracy: 0.9848\n","390/696 [===============>..............] - ETA: 6s - loss: 0.0514 - accuracy: 0.9845\u001b[32m [repeated 10x across cluster]\u001b[0m\n","392/696 [===============>..............] - ETA: 6s - loss: 0.0517 - accuracy: 0.9844\u001b[32m [repeated 6x across cluster]\u001b[0m\n","627/696 [==========================>...] - ETA: 1s - loss: 0.0486 - accuracy: 0.9847\n","630/696 [==========================>...] - ETA: 1s - loss: 0.0485 - accuracy: 0.9847\n","396/696 [================>.............] - ETA: 6s - loss: 0.0512 - accuracy: 0.9845\u001b[32m [repeated 2x across cluster]\u001b[0m\n","414/696 [================>.............] - ETA: 6s - loss: 0.0513 - accuracy: 0.9844\u001b[32m [repeated 6x across cluster]\u001b[0m\n","636/696 [==========================>...] - ETA: 1s - loss: 0.0486 - accuracy: 0.9847\n","416/696 [================>.............] - ETA: 6s - loss: 0.0510 - accuracy: 0.9845\u001b[32m [repeated 8x across cluster]\u001b[0m\n","651/696 [===========================>..] - ETA: 0s - loss: 0.0477 - accuracy: 0.9848\n","651/696 [===========================>..] - ETA: 0s - loss: 0.0477 - accuracy: 0.9848\n","438/696 [=================>............] - ETA: 5s - loss: 0.0509 - accuracy: 0.9842\u001b[32m [repeated 7x across cluster]\u001b[0m\n","654/696 [===========================>..] - ETA: 0s - loss: 0.0477 - accuracy: 0.9848\n","440/696 [=================>............] - ETA: 5s - loss: 0.0508 - accuracy: 0.9842\u001b[32m [repeated 8x across cluster]\u001b[0m\n","660/696 [===========================>..] - ETA: 0s - loss: 0.0476 - accuracy: 0.9848\n","675/696 [============================>.] - ETA: 0s - loss: 0.0494 - accuracy: 0.9848\n","675/696 [============================>.] - ETA: 0s - loss: 0.0494 - accuracy: 0.9848\n","676/696 [============================>.] - ETA: 0s - loss: 0.0494 - accuracy: 0.9848\n","462/696 [==================>...........] - ETA: 5s - loss: 0.0500 - accuracy: 0.9842\u001b[32m [repeated 7x across cluster]\u001b[0m\n","678/696 [============================>.] - ETA: 0s - loss: 0.0494 - accuracy: 0.9848\n","459/696 [==================>...........] - ETA: 5s - loss: 0.0503 - accuracy: 0.9841\u001b[32m [repeated 8x across cluster]\u001b[0m\n"]},{"output_type":"stream","name":"stderr","text":["DEBUG flwr 2023-06-25 07:27:41,868 | server.py:182 | evaluate_round 5 received 4 results and 0 failures\n","DEBUG:flwr:evaluate_round 5 received 4 results and 0 failures\n","INFO flwr 2023-06-25 07:27:41,870 | server.py:147 | FL finished in 1826.939739032\n","INFO:flwr:FL finished in 1826.939739032\n","INFO flwr 2023-06-25 07:27:41,872 | app.py:218 | app_fit: losses_distributed [(1, 15.61662483215332), (2, 0.1407310664653778), (3, 0.16205665469169617), (4, 0.09429912269115448), (5, 0.0498260073363781)]\n","INFO:flwr:app_fit: losses_distributed [(1, 15.61662483215332), (2, 0.1407310664653778), (3, 0.16205665469169617), (4, 0.09429912269115448), (5, 0.0498260073363781)]\n","INFO flwr 2023-06-25 07:27:41,877 | app.py:219 | app_fit: metrics_distributed_fit {}\n","INFO:flwr:app_fit: metrics_distributed_fit {}\n","INFO flwr 2023-06-25 07:27:41,879 | app.py:220 | app_fit: metrics_distributed {}\n","INFO:flwr:app_fit: metrics_distributed {}\n","INFO flwr 2023-06-25 07:27:41,882 | app.py:221 | app_fit: losses_centralized [(0, 1.6153745651245117), (1, 15.616620063781738), (2, 0.14071901142597198), (3, 0.16205409169197083), (4, 0.0943123921751976), (5, 0.049816686660051346)]\n","INFO:flwr:app_fit: losses_centralized [(0, 1.6153745651245117), (1, 15.616620063781738), (2, 0.14071901142597198), (3, 0.16205409169197083), (4, 0.0943123921751976), (5, 0.049816686660051346)]\n","INFO flwr 2023-06-25 07:27:41,884 | app.py:222 | app_fit: metrics_centralized {'accuracy': [(0, 0.029874213836477988), (1, 0.5149146451033243), (2, 0.9530098831985624), (3, 0.9649595687331537), (4, 0.9769991015274034), (5, 0.9847259658580413)], 'precision': [(0, 0.5316927685061484), (1, 0.6579297589424614), (2, 0.9533867020479112), (3, 0.9668094854590402), (4, 0.9768047521299331), (5, 0.9848300640330876)], 'recall': [(0, 0.029874213836477988), (1, 0.5149146451033243), (2, 0.9530098831985624), (3, 0.9649595687331537), (4, 0.9769991015274034), (5, 0.9847259658580413)], 'f1-score': [(0, 0.019378919018970174), (1, 0.35278709239213984), (2, 0.9496820899686648), (3, 0.9636704668218635), (4, 0.9766756844094651), (5, 0.9841044000402451)]}\n","INFO:flwr:app_fit: metrics_centralized {'accuracy': [(0, 0.029874213836477988), (1, 0.5149146451033243), (2, 0.9530098831985624), (3, 0.9649595687331537), (4, 0.9769991015274034), (5, 0.9847259658580413)], 'precision': [(0, 0.5316927685061484), (1, 0.6579297589424614), (2, 0.9533867020479112), (3, 0.9668094854590402), (4, 0.9768047521299331), (5, 0.9848300640330876)], 'recall': [(0, 0.029874213836477988), (1, 0.5149146451033243), (2, 0.9530098831985624), (3, 0.9649595687331537), (4, 0.9769991015274034), (5, 0.9847259658580413)], 'f1-score': [(0, 0.019378919018970174), (1, 0.35278709239213984), (2, 0.9496820899686648), (3, 0.9636704668218635), (4, 0.9766756844094651), (5, 0.9841044000402451)]}\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[2m\u001b[36m(launch_and_evaluate pid=3044)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r696/696 [==============================] - ETA: 0s - loss: 0.0498 - accuracy: 0.9847\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r696/696 [==============================] - 16s 22ms/step - loss: 0.0498 - accuracy: 0.9847\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3053)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r461/696 [==================>...........] - ETA: 5s - loss: 0.0501 - accuracy: 0.9842\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r464/696 [===================>..........] - ETA: 5s - loss: 0.0499 - accuracy: 0.9843\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3053)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r695/696 [============================>.] - ETA: 0s - loss: 0.0497 - accuracy: 0.9848\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r696/696 [==============================] - 16s 22ms/step - loss: 0.0498 - accuracy: 0.9847\n"]}],"source":["hist = fl.simulation.start_simulation(\n","    client_fn= gen_client,\n","    clients_ids=client_ids_list,\n","    config=fl.server.ServerConfig(num_rounds=5),\n","    strategy=strategy,\n","    client_resources=None,\n",")"]},{"cell_type":"code","execution_count":42,"metadata":{"id":"sUyamtncEIZO","executionInfo":{"status":"ok","timestamp":1687678063279,"user_tz":-60,"elapsed":941,"user":{"displayName":"collab","userId":"14061672705760794442"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"5a20c369-5672-49e4-ed52-f0b98bd26b2e"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2m\u001b[36m(launch_and_evaluate pid=3052)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r486/696 [===================>..........] - ETA: 4s - loss: 0.0496 - accuracy: 0.9845\u001b[32m [repeated 10x across cluster]\u001b[0m\n","\u001b[2m\u001b[36m(launch_and_evaluate pid=3052)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r480/696 [===================>..........] - ETA: 4s - loss: 0.0501 - accuracy: 0.9844\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r483/696 [===================>..........] - ETA: 4s - loss: 0.0498 - accuracy: 0.9845\u001b[32m [repeated 7x across cluster]\u001b[0m\n"]}],"source":["modelfl = build_model()\n","modelfl.set_weights(fl_weights)\n","\n","modelfl.save('/content/drive/MyDrive/Colab Notebooks/h5 models/FedAdgrad-Federated-model.h5')"]},{"cell_type":"code","execution_count":43,"metadata":{"id":"DO8l1MKf5wmZ","colab":{"base_uri":"https://localhost:8080/","height":448},"executionInfo":{"status":"ok","timestamp":1687678063280,"user_tz":-60,"elapsed":10,"user":{"displayName":"collab","userId":"14061672705760794442"}},"outputId":"4fdb1819-619a-426d-c3dc-7bf22fce4a20"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1500x500 with 2 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["loss = [i[1] for i in hist.losses_centralized]\n","acc = [i[1] for i in hist.metrics_centralized[\"accuracy\"]]\n","\n","# plot training history, loss and accuracy side by side\n","_, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n","_min = np.min(loss)\n","ax1.axhline(y=_min, label=f\"Min: {_min:.4f}\", linestyle='--', color='lightcoral')\n","ax1.plot(loss)\n","ax1.set_ylabel('Loss')\n","ax1.set_xlabel('Epoch')\n","ax1.legend()\n","_max = np.max(acc)\n","ax2.axhline(y=_max, label=f\"Max: {_max:.4f}\", linestyle='--', color='lightcoral')\n","ax2.plot(acc, color='orange')\n","ax2.set_ylabel('Accuracy')\n","ax2.set_xlabel('Epoch')\n","ax2.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":43,"metadata":{"id":"zHq7kGxHBt9v","executionInfo":{"status":"ok","timestamp":1687678063281,"user_tz":-60,"elapsed":8,"user":{"displayName":"collab","userId":"14061672705760794442"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":44,"metadata":{"id":"RTz6SRIs0QcP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687678069784,"user_tz":-60,"elapsed":6511,"user":{"displayName":"collab","userId":"14061672705760794442"}},"outputId":"5754cba1-18f2-436d-9f18-ead8951af7cf"},"outputs":[{"output_type":"stream","name":"stdout","text":["696/696 [==============================] - 3s 3ms/step\n"]},{"output_type":"execute_result","data":{"text/plain":["(array([[11435,     9,    12,     5,     1],\n","        [   31,  8021,     2,     0,     0],\n","        [  102,     1,  2022,     0,     0],\n","        [  161,     0,     1,   406,     2],\n","        [    9,     0,     0,     4,    36]]),\n"," {'accuracy': 0.9847259658580413,\n","  'precision': 0.9848300640330876,\n","  'recall': 0.9847259658580413,\n","  'f1-score': 0.9841044000402451},\n"," 0.049816686660051346)"]},"metadata":{},"execution_count":44}],"source":["evaluate_model1(modelfl, x_test, y_test)"]},{"cell_type":"code","source":["result_df = write_metrics_to_dataframe(\"model_fl \"+config, calculate_metrics(y_test, modelfl.predict(x_test)), result_df)\n","result_df.to_csv(\"/content/drive/MyDrive/Colab Notebooks/FL\"+config+\".txt\", index = False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Euorv7QkPhAN","executionInfo":{"status":"ok","timestamp":1687678212737,"user_tz":-60,"elapsed":2738,"user":{"displayName":"collab","userId":"14061672705760794442"}},"outputId":"1090a080-3732-4577-9f2e-254735c45b57"},"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["696/696 [==============================] - 2s 3ms/step\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-32-630fbd364ecf>:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  df = df.append(metrics_dict, ignore_index=True)\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[{"file_id":"1aA1MdGZTFdbirEuINAdHV5PYsLe96hrd","timestamp":1685757280119}],"gpuType":"A100"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}