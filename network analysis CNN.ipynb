{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c15fb6d4",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcd8be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f948a18",
   "metadata": {},
   "source": [
    "### DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e819ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# possible features to use for connection oriented traces ?\n",
    "\n",
    "# [\"duration\",\"protocol_type\", \"service\",\"flag\",\"src_bytes\",\"dst_bytes\",\"wrong_fragment\",\"count\",\"srv_count\",\"serror_rate\",\"srv_serror_rate\",\"rerror_rate\",\"srv_rerror_rate\",\"same_srv_rate\", \"diff_srv_rate\",\"dst_host_count\",\"dst_host_srv_count\",\"dst_host_same_srv_rate\",\"dst_host_diff_srv_rate\",\"class\"]\n",
    "# words_list = ['duration', 'src_bytes', 'dst_bytes', 'land', 'wrong_fragment', 'urgent', 'hot', 'num_failed_logins', 'logged_in', 'num_compromised', 'root_shell', 'su_attempted', 'num_root', 'num_file_creations', 'num_shells', 'num_access_files', 'num_outbound_cmds', 'is_host_login', 'is_guest_login', 'count', 'srv_count', 'serror_rate', 'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb43d941",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['duration','protocol_type','service','flag','src_bytes','dst_bytes','land','wrong_fragment','urgent','hot',\n",
    "            'num_failed_logins','logged_in','num_compromised','root_shell','su_attempted','num_root','num_file_creations',\n",
    "            'num_shells','num_access_files','num_outbound_cmds','is_host_login','is_guest_login','count','srv_count','serror_rate',\n",
    "            'srv_serror_rate','rerror_rate','srv_rerror_rate','same_srv_rate','diff_srv_rate','srv_diff_host_rate','dst_host_count',\n",
    "            'dst_host_srv_count','dst_host_same_srv_rate','dst_host_diff_srv_rate','dst_host_same_src_port_rate',\n",
    "            'dst_host_srv_diff_host_rate','dst_host_serror_rate','dst_host_srv_serror_rate','dst_host_rerror_rate',\n",
    "            'dst_host_srv_rerror_rate','class','difficulty_level']\n",
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d24de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"KDDTrain+20.txt\", names = features)\n",
    "test_df = pd.read_csv(\"KDDTest+20.txt\", names = features)\n",
    "\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c13e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make some stats"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "de4c06a2",
   "metadata": {},
   "source": [
    "### DATA Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd0f911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# droping last column bc we don't need it\n",
    "\n",
    "train_df = train_df.drop(\"difficulty_level\", 1)\n",
    "test_df = test_df.drop(\"difficulty_level\",1)\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb814b83",
   "metadata": {},
   "source": [
    "#shows different problems\n",
    "def spot( a, b):\n",
    "    diff = []\n",
    "\n",
    "    for each in a:\n",
    "        if each not in b:\n",
    "            diff.append(each)\n",
    "    for el in b:\n",
    "        if el not in a:\n",
    "            diff.append(el)\n",
    "    return diff\n",
    "#['protocol_type','service','flag']\n",
    "s = \"service\"\n",
    "diff = spot(train_df[s].unique(),test_df[s].unique())\n",
    "print(diff)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "09750131",
   "metadata": {},
   "source": [
    "##### One-hot encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9427d141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# these feautures have categorical values\n",
    "columns = ['protocol_type','service','flag']\n",
    "\n",
    "\n",
    "def one_hot(dataframe, columns):\n",
    "    \n",
    "    for col in columns:\n",
    "        dummies = pd.get_dummies(dataframe[col], prefix=col, drop_first= False)\n",
    "        dataframe = pd.concat([dataframe, dummies], axis= 1)\n",
    "        dataframe = dataframe.drop(col, 1)\n",
    "    return dataframe\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16c5626",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df1 = one_hot(train_df, columns)\n",
    "test_df1 = one_hot(test_df, columns )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ca27cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#should be (125973, 123)\n",
    "#print(\"TRAIN DF\",train_df1.shape)\n",
    "print(\"TEST DF\",test_df1.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5d31c501",
   "metadata": {},
   "source": [
    "##### Drop unnecessary features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1859bdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_class = train_df1.pop('class')\n",
    "test_class = test_df1.pop('class')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e78f8e40",
   "metadata": {},
   "source": [
    "##### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444c61ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization will be applied to all features\n",
    "\n",
    "def normalize(dataframe, columns):\n",
    "    temp = dataframe.copy()\n",
    "    for col in columns:\n",
    "        max_val = dataframe[col].max()\n",
    "        min_val = dataframe[col].min()\n",
    "        if max_val>min_val:\n",
    "            temp[col] = (dataframe[col] - min_val)/(max_val - min_val)\n",
    "    \n",
    "    return temp\n",
    "\n",
    "train_df2 = normalize(train_df1, train_df1.columns)\n",
    "test_df2 = normalize(test_df1, test_df1.columns)\n",
    "\n",
    "train_df2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "36a011a3",
   "metadata": {},
   "source": [
    "##### Fixing class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fixing train and test class set labels\n",
    "classlist_train = []\n",
    "classlist_test = []\n",
    "\n",
    "Dos_class = (\"apache2\",\"back\",\"land\",\"neptune\",\"mailbomb\",\"pod\",\"processtable\",\"smurf\",\"teardrop\",\"udpstorm\",\"worm\")\n",
    "Probe_class = (\"ipsweep\",\"mscan\",\"nmap\",\"portsweep\",\"saint\",\"satan\")\n",
    "U2R_class = (\"buffer_overflow\",\"loadmodule\",\"perl\",\"ps\",\"rootkit\",\"sqlattack\",\"xterm\")\n",
    "R2L_class = (\"ftp_write\",\"guess_passwd\",\"httptunnel\",\"imap\",\"multihop\",\"named\",\"phf\",\"sendmail\",\"Snmpgetattack\",\"spy\",\"snmpguess\",\"warezclient\",\"warezmaster\",\"xlock\",\"xsnoop\")\n",
    "\n",
    "#counting lables\n",
    "\n",
    "DoSCount_train=0\n",
    "ProbeCount_train=0\n",
    "U2RCount_train=0\n",
    "R2LCount_train=0\n",
    "NormalCount_train=0\n",
    "\n",
    "DoSCount_test=0\n",
    "ProbeCount_test=0\n",
    "U2RCount_test=0\n",
    "R2LCount_test=0\n",
    "NormalCount_test=0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3a308c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fixing labels for training set\n",
    "for item in train_class:\n",
    "    if item in Dos_class:\n",
    "        classlist_train.append(\"DoS\")\n",
    "        DoSCount_train=DoSCount_train+1\n",
    "    elif item in Probe_class:\n",
    "        classlist_train.append(\"Probe\")\n",
    "        ProbeCount_train=ProbeCount_train+1\n",
    "    elif item in U2R_class:\n",
    "        classlist_train.append(\"U2R\")\n",
    "        U2RCount_train=U2RCount_train+1\n",
    "    elif item in R2L_class:\n",
    "        classlist_train.append(\"R2L\")\n",
    "        R2LCount_train=R2LCount_train+1\n",
    "    else:\n",
    "        classlist_train.append(\"Normal\")\n",
    "        NormalCount_train=NormalCount_train+1\n",
    "\n",
    "print(\"Train class count\")\n",
    "print(DoSCount_train)\n",
    "print(NormalCount_train)\n",
    "print(ProbeCount_train)\n",
    "print(R2LCount_train)\n",
    "print(U2RCount_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704c9061",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fixing labels for testing set\n",
    "for item in test_class:\n",
    "    if item in Dos_class:\n",
    "        classlist_test.append(\"DoS\")\n",
    "        DoSCount_test=DoSCount_test+1\n",
    "    elif item in Probe_class:\n",
    "        classlist_test.append(\"Probe\")\n",
    "        ProbeCount_test=ProbeCount_test+1\n",
    "    elif item in U2R_class:\n",
    "        classlist_test.append(\"U2R\")\n",
    "        U2RCount_test=U2RCount_test+1\n",
    "    elif item in R2L_class:\n",
    "        classlist_test.append(\"R2L\")\n",
    "        R2LCount_test=R2LCount_test+1\n",
    "    else:\n",
    "        classlist_test.append(\"Normal\")\n",
    "        NormalCount_test=NormalCount_test+1\n",
    "\n",
    "print(\"Test class count\")\n",
    "print(DoSCount_test)\n",
    "print(NormalCount_test)\n",
    "print(ProbeCount_test)\n",
    "print(R2LCount_test)\n",
    "print(U2RCount_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bcbfee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding back class feature to normalized train and test set\n",
    "\n",
    "train_df2[\"class\"] = classlist_train\n",
    "test_df2[\"class\"] =  classlist_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6153ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_df2.shape)\n",
    "print(test_df2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020f2cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = train_df2[\"class\"]\n",
    "Y_test = test_df2[\"class\"]\n",
    "\n",
    "X_train = train_df2.drop(\"class\",1)\n",
    "X_test = test_df2.drop(\"class\",1)\n",
    "X_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d0adaaf3",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4182f8c4",
   "metadata": {},
   "source": [
    "##### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8105e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Define the CNN architecture\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(25, 1)),\n",
    "    keras.layers.MaxPooling1D(pool_size=2),\n",
    "    keras.layers.Conv1D(filters=128, kernel_size=3, activation='relu'),\n",
    "    keras.layers.MaxPooling1D(pool_size=2),\n",
    "    keras.layers.Conv1D(filters=256, kernel_size=3, activation='relu'),\n",
    "    keras.layers.MaxPooling1D(pool_size=2),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(units=1024, activation='relu'),\n",
    "    keras.layers.Dense(units=512, activation='relu'),\n",
    "    keras.layers.Dense(units=5, activation='softmax') # 5 output classes for multiclass classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val))\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', test_acc)\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac16deb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "\n",
    "\n",
    "cnn = Sequential()\n",
    "cnn.add(Convolution1D(64, 3, padding=\"same\", activation=\"relu\", input_shape=(117, 1)))\n",
    "cnn.add(Convolution1D(64, 3, padding=\"same\", activation=\"relu\"))\n",
    "cnn.add(MaxPooling1D(pool_size=2))\n",
    "cnn.add(Convolution1D(128, 3, padding=\"same\", activation=\"relu\"))\n",
    "cnn.add(Convolution1D(128, 3, padding=\"same\", activation=\"relu\"))\n",
    "cnn.add(MaxPooling1D(pool_size=2))\n",
    "cnn.add(Flatten())\n",
    "cnn.add(Dense(128, activation=\"relu\"))\n",
    "cnn.add(Dropout(0.1))\n",
    "cnn.add(Dense(128, activation=\"relu\"))\n",
    "cnn.add(Dropout(0.1))\n",
    "cnn.add(Dense(64, activation=\"relu\"))\n",
    "cnn.add(Dropout(0.1))\n",
    "cnn.add(Dense(64, activation=\"relu\"))\n",
    "cnn.add(Dropout(0.1))\n",
    "cnn.add(Dense(5, activation=\"softmax\"))\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "cnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce6be39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting data 80/20\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(X_train, Y_train, test_size=0.2, random_state=101)\n",
    "\n",
    "train_X = MinMaxScaler().fit_transform(train_X)\n",
    "test_x = MinMaxScaler().fit_transform(test_X)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5a0808",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_df2.shape)\n",
    "x_columns_train = train_df2.columns.drop('class')\n",
    "print(x_columns_train.shape)\n",
    "x_train_array = train_df2[x_columns_train].values\n",
    "x_train_1=np.reshape(x_train_array, (x_train_array.shape[0], x_train_array.shape[1], 1))\n",
    "    \n",
    "dummies_train = pd.get_dummies(Y_train) # Classification\n",
    "outcomes = dummies_train.columns\n",
    "num_classes = len(outcomes)\n",
    "y_train_1 = dummies_train.values\n",
    "\n",
    "x_columns_test = test_df2.columns.drop('class')\n",
    "\n",
    "x_test_array = test_df2[x_columns_test].values\n",
    "x_test_1=np.reshape(x_test_array, (x_test_array.shape[0], x_test_array.shape[1], 1))\n",
    "    \n",
    "dummies_test = pd.get_dummies(Y_test) # Classification\n",
    "outcomes_test = dummies_test.columns\n",
    "num_classes = len(outcomes_test)\n",
    "y_test_1 = dummies_test.values  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1a50ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train_1.shape)\n",
    "print(y_train_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c485e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "history= cnn.fit(x_train_1, y_train_1,validation_data=(x_test_1,y_test_1), epochs=50) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
